{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 7500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.004,
      "grad_norm": 1.9144654273986816,
      "learning_rate": 1.9976000000000003e-05,
      "loss": 1.0975,
      "step": 10
    },
    {
      "epoch": 0.008,
      "grad_norm": 2.8387537002563477,
      "learning_rate": 1.9949333333333332e-05,
      "loss": 0.3506,
      "step": 20
    },
    {
      "epoch": 0.012,
      "grad_norm": 0.8940328359603882,
      "learning_rate": 1.9922666666666668e-05,
      "loss": 0.3205,
      "step": 30
    },
    {
      "epoch": 0.016,
      "grad_norm": 1.0563514232635498,
      "learning_rate": 1.9896e-05,
      "loss": 0.2124,
      "step": 40
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.4049749374389648,
      "learning_rate": 1.9869333333333336e-05,
      "loss": 0.1606,
      "step": 50
    },
    {
      "epoch": 0.024,
      "grad_norm": 0.8384636044502258,
      "learning_rate": 1.984266666666667e-05,
      "loss": 0.1162,
      "step": 60
    },
    {
      "epoch": 0.028,
      "grad_norm": 0.4578759968280792,
      "learning_rate": 1.9816e-05,
      "loss": 0.1414,
      "step": 70
    },
    {
      "epoch": 0.032,
      "grad_norm": 0.45615485310554504,
      "learning_rate": 1.9789333333333337e-05,
      "loss": 0.1033,
      "step": 80
    },
    {
      "epoch": 0.036,
      "grad_norm": 0.9521483778953552,
      "learning_rate": 1.9762666666666666e-05,
      "loss": 0.0873,
      "step": 90
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.8555276393890381,
      "learning_rate": 1.9736000000000002e-05,
      "loss": 0.0759,
      "step": 100
    },
    {
      "epoch": 0.044,
      "grad_norm": 1.5268375873565674,
      "learning_rate": 1.9709333333333335e-05,
      "loss": 0.0715,
      "step": 110
    },
    {
      "epoch": 0.048,
      "grad_norm": 2.6175825595855713,
      "learning_rate": 1.9682666666666667e-05,
      "loss": 0.0969,
      "step": 120
    },
    {
      "epoch": 0.052,
      "grad_norm": 0.9301509857177734,
      "learning_rate": 1.9656000000000003e-05,
      "loss": 0.0675,
      "step": 130
    },
    {
      "epoch": 0.056,
      "grad_norm": 1.0243796110153198,
      "learning_rate": 1.9629333333333335e-05,
      "loss": 0.0514,
      "step": 140
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.32098624110221863,
      "learning_rate": 1.9602666666666668e-05,
      "loss": 0.0718,
      "step": 150
    },
    {
      "epoch": 0.064,
      "grad_norm": 0.8339120745658875,
      "learning_rate": 1.9576e-05,
      "loss": 0.0701,
      "step": 160
    },
    {
      "epoch": 0.068,
      "grad_norm": 1.6008684635162354,
      "learning_rate": 1.9549333333333336e-05,
      "loss": 0.0599,
      "step": 170
    },
    {
      "epoch": 0.072,
      "grad_norm": 0.8502951860427856,
      "learning_rate": 1.952266666666667e-05,
      "loss": 0.0579,
      "step": 180
    },
    {
      "epoch": 0.076,
      "grad_norm": 0.6710843443870544,
      "learning_rate": 1.9496e-05,
      "loss": 0.0593,
      "step": 190
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.570174217224121,
      "learning_rate": 1.9469333333333337e-05,
      "loss": 0.0449,
      "step": 200
    },
    {
      "epoch": 0.084,
      "grad_norm": 1.5650352239608765,
      "learning_rate": 1.9442666666666666e-05,
      "loss": 0.0445,
      "step": 210
    },
    {
      "epoch": 0.088,
      "grad_norm": 0.6078166365623474,
      "learning_rate": 1.9416000000000002e-05,
      "loss": 0.0592,
      "step": 220
    },
    {
      "epoch": 0.092,
      "grad_norm": 1.7465651035308838,
      "learning_rate": 1.9389333333333334e-05,
      "loss": 0.0381,
      "step": 230
    },
    {
      "epoch": 0.096,
      "grad_norm": 0.9740085601806641,
      "learning_rate": 1.9362666666666667e-05,
      "loss": 0.0411,
      "step": 240
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.72655189037323,
      "learning_rate": 1.9336000000000003e-05,
      "loss": 0.052,
      "step": 250
    },
    {
      "epoch": 0.104,
      "grad_norm": 0.7652058601379395,
      "learning_rate": 1.9309333333333335e-05,
      "loss": 0.0274,
      "step": 260
    },
    {
      "epoch": 0.108,
      "grad_norm": 1.043049693107605,
      "learning_rate": 1.9282666666666667e-05,
      "loss": 0.0404,
      "step": 270
    },
    {
      "epoch": 0.112,
      "grad_norm": 0.7618403434753418,
      "learning_rate": 1.9256e-05,
      "loss": 0.0449,
      "step": 280
    },
    {
      "epoch": 0.116,
      "grad_norm": 1.0462833642959595,
      "learning_rate": 1.9229333333333336e-05,
      "loss": 0.0611,
      "step": 290
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.42636585235595703,
      "learning_rate": 1.9202666666666668e-05,
      "loss": 0.0234,
      "step": 300
    },
    {
      "epoch": 0.124,
      "grad_norm": 0.14376601576805115,
      "learning_rate": 1.9176e-05,
      "loss": 0.03,
      "step": 310
    },
    {
      "epoch": 0.128,
      "grad_norm": 0.5943450331687927,
      "learning_rate": 1.9149333333333337e-05,
      "loss": 0.043,
      "step": 320
    },
    {
      "epoch": 0.132,
      "grad_norm": 0.6793394684791565,
      "learning_rate": 1.9122666666666666e-05,
      "loss": 0.0274,
      "step": 330
    },
    {
      "epoch": 0.136,
      "grad_norm": 2.449923038482666,
      "learning_rate": 1.9096e-05,
      "loss": 0.0482,
      "step": 340
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.43408703804016113,
      "learning_rate": 1.9069333333333334e-05,
      "loss": 0.036,
      "step": 350
    },
    {
      "epoch": 0.144,
      "grad_norm": 1.150631308555603,
      "learning_rate": 1.904266666666667e-05,
      "loss": 0.0522,
      "step": 360
    },
    {
      "epoch": 0.148,
      "grad_norm": 0.47658151388168335,
      "learning_rate": 1.9016000000000002e-05,
      "loss": 0.0351,
      "step": 370
    },
    {
      "epoch": 0.152,
      "grad_norm": 0.6615406274795532,
      "learning_rate": 1.8989333333333335e-05,
      "loss": 0.0489,
      "step": 380
    },
    {
      "epoch": 0.156,
      "grad_norm": 0.3046351671218872,
      "learning_rate": 1.896266666666667e-05,
      "loss": 0.0581,
      "step": 390
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.4158013164997101,
      "learning_rate": 1.8936e-05,
      "loss": 0.0262,
      "step": 400
    },
    {
      "epoch": 0.164,
      "grad_norm": 0.4678680896759033,
      "learning_rate": 1.8909333333333335e-05,
      "loss": 0.0206,
      "step": 410
    },
    {
      "epoch": 0.168,
      "grad_norm": 0.8461373448371887,
      "learning_rate": 1.8882666666666668e-05,
      "loss": 0.0382,
      "step": 420
    },
    {
      "epoch": 0.172,
      "grad_norm": 0.5794620513916016,
      "learning_rate": 1.8856e-05,
      "loss": 0.0292,
      "step": 430
    },
    {
      "epoch": 0.176,
      "grad_norm": 0.5364700555801392,
      "learning_rate": 1.8829333333333336e-05,
      "loss": 0.0197,
      "step": 440
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.583089292049408,
      "learning_rate": 1.880266666666667e-05,
      "loss": 0.0292,
      "step": 450
    },
    {
      "epoch": 0.184,
      "grad_norm": 0.6051719188690186,
      "learning_rate": 1.8776e-05,
      "loss": 0.0321,
      "step": 460
    },
    {
      "epoch": 0.188,
      "grad_norm": 0.20114575326442719,
      "learning_rate": 1.8749333333333334e-05,
      "loss": 0.032,
      "step": 470
    },
    {
      "epoch": 0.192,
      "grad_norm": 0.5592367053031921,
      "learning_rate": 1.872266666666667e-05,
      "loss": 0.0293,
      "step": 480
    },
    {
      "epoch": 0.196,
      "grad_norm": 0.24909554421901703,
      "learning_rate": 1.8696000000000002e-05,
      "loss": 0.0438,
      "step": 490
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.6172900199890137,
      "learning_rate": 1.8669333333333334e-05,
      "loss": 0.0379,
      "step": 500
    },
    {
      "epoch": 0.204,
      "grad_norm": 0.5805320739746094,
      "learning_rate": 1.864266666666667e-05,
      "loss": 0.0209,
      "step": 510
    },
    {
      "epoch": 0.208,
      "grad_norm": 0.6848642230033875,
      "learning_rate": 1.8616e-05,
      "loss": 0.0272,
      "step": 520
    },
    {
      "epoch": 0.212,
      "grad_norm": 0.985207736492157,
      "learning_rate": 1.8589333333333335e-05,
      "loss": 0.0314,
      "step": 530
    },
    {
      "epoch": 0.216,
      "grad_norm": 0.8163833022117615,
      "learning_rate": 1.8562666666666668e-05,
      "loss": 0.0255,
      "step": 540
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.6441763043403625,
      "learning_rate": 1.8536e-05,
      "loss": 0.0249,
      "step": 550
    },
    {
      "epoch": 0.224,
      "grad_norm": 1.110872745513916,
      "learning_rate": 1.8509333333333336e-05,
      "loss": 0.021,
      "step": 560
    },
    {
      "epoch": 0.228,
      "grad_norm": 1.3922555446624756,
      "learning_rate": 1.848266666666667e-05,
      "loss": 0.0553,
      "step": 570
    },
    {
      "epoch": 0.232,
      "grad_norm": 0.9760690331459045,
      "learning_rate": 1.8456e-05,
      "loss": 0.0333,
      "step": 580
    },
    {
      "epoch": 0.236,
      "grad_norm": 0.5105693936347961,
      "learning_rate": 1.8429333333333333e-05,
      "loss": 0.0267,
      "step": 590
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.0168068408966064,
      "learning_rate": 1.840266666666667e-05,
      "loss": 0.0383,
      "step": 600
    },
    {
      "epoch": 0.244,
      "grad_norm": 2.2871553897857666,
      "learning_rate": 1.8376e-05,
      "loss": 0.0229,
      "step": 610
    },
    {
      "epoch": 0.248,
      "grad_norm": 0.7361642122268677,
      "learning_rate": 1.8349333333333334e-05,
      "loss": 0.0188,
      "step": 620
    },
    {
      "epoch": 0.252,
      "grad_norm": 0.7715261578559875,
      "learning_rate": 1.832266666666667e-05,
      "loss": 0.0349,
      "step": 630
    },
    {
      "epoch": 0.256,
      "grad_norm": 0.5812736749649048,
      "learning_rate": 1.8296e-05,
      "loss": 0.0277,
      "step": 640
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.796759009361267,
      "learning_rate": 1.8269333333333335e-05,
      "loss": 0.0286,
      "step": 650
    },
    {
      "epoch": 0.264,
      "grad_norm": 0.45906493067741394,
      "learning_rate": 1.8242666666666667e-05,
      "loss": 0.0231,
      "step": 660
    },
    {
      "epoch": 0.268,
      "grad_norm": 0.5432606339454651,
      "learning_rate": 1.8216000000000003e-05,
      "loss": 0.0213,
      "step": 670
    },
    {
      "epoch": 0.272,
      "grad_norm": 0.6148509979248047,
      "learning_rate": 1.8189333333333336e-05,
      "loss": 0.0307,
      "step": 680
    },
    {
      "epoch": 0.276,
      "grad_norm": 0.36247536540031433,
      "learning_rate": 1.8162666666666668e-05,
      "loss": 0.0212,
      "step": 690
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.2511661946773529,
      "learning_rate": 1.8136000000000004e-05,
      "loss": 0.0265,
      "step": 700
    },
    {
      "epoch": 0.284,
      "grad_norm": 0.19265641272068024,
      "learning_rate": 1.8109333333333333e-05,
      "loss": 0.0293,
      "step": 710
    },
    {
      "epoch": 0.288,
      "grad_norm": 0.8661718964576721,
      "learning_rate": 1.808266666666667e-05,
      "loss": 0.0349,
      "step": 720
    },
    {
      "epoch": 0.292,
      "grad_norm": 0.29436734318733215,
      "learning_rate": 1.8056e-05,
      "loss": 0.0323,
      "step": 730
    },
    {
      "epoch": 0.296,
      "grad_norm": 0.26468905806541443,
      "learning_rate": 1.8029333333333334e-05,
      "loss": 0.0303,
      "step": 740
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.5130387544631958,
      "learning_rate": 1.800266666666667e-05,
      "loss": 0.0274,
      "step": 750
    },
    {
      "epoch": 0.304,
      "grad_norm": 1.1708118915557861,
      "learning_rate": 1.7976000000000002e-05,
      "loss": 0.0395,
      "step": 760
    },
    {
      "epoch": 0.308,
      "grad_norm": 0.36977362632751465,
      "learning_rate": 1.7949333333333335e-05,
      "loss": 0.0266,
      "step": 770
    },
    {
      "epoch": 0.312,
      "grad_norm": 0.5551632642745972,
      "learning_rate": 1.7922666666666667e-05,
      "loss": 0.0159,
      "step": 780
    },
    {
      "epoch": 0.316,
      "grad_norm": 0.6713928580284119,
      "learning_rate": 1.7896000000000003e-05,
      "loss": 0.031,
      "step": 790
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.44474613666534424,
      "learning_rate": 1.7869333333333335e-05,
      "loss": 0.0173,
      "step": 800
    },
    {
      "epoch": 0.324,
      "grad_norm": 0.7366455793380737,
      "learning_rate": 1.7842666666666668e-05,
      "loss": 0.0284,
      "step": 810
    },
    {
      "epoch": 0.328,
      "grad_norm": 0.3264795243740082,
      "learning_rate": 1.7816000000000004e-05,
      "loss": 0.0138,
      "step": 820
    },
    {
      "epoch": 0.332,
      "grad_norm": 0.1624291092157364,
      "learning_rate": 1.7789333333333333e-05,
      "loss": 0.029,
      "step": 830
    },
    {
      "epoch": 0.336,
      "grad_norm": 0.3103550374507904,
      "learning_rate": 1.776266666666667e-05,
      "loss": 0.0411,
      "step": 840
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.5837699174880981,
      "learning_rate": 1.7736e-05,
      "loss": 0.0235,
      "step": 850
    },
    {
      "epoch": 0.344,
      "grad_norm": 0.7051272988319397,
      "learning_rate": 1.7709333333333333e-05,
      "loss": 0.0114,
      "step": 860
    },
    {
      "epoch": 0.348,
      "grad_norm": 0.9320617318153381,
      "learning_rate": 1.768266666666667e-05,
      "loss": 0.0171,
      "step": 870
    },
    {
      "epoch": 0.352,
      "grad_norm": 0.7980935573577881,
      "learning_rate": 1.7656000000000002e-05,
      "loss": 0.0329,
      "step": 880
    },
    {
      "epoch": 0.356,
      "grad_norm": 0.35273751616477966,
      "learning_rate": 1.7629333333333334e-05,
      "loss": 0.0443,
      "step": 890
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.7668852806091309,
      "learning_rate": 1.7602666666666667e-05,
      "loss": 0.0222,
      "step": 900
    },
    {
      "epoch": 0.364,
      "grad_norm": 0.5601364374160767,
      "learning_rate": 1.7576000000000002e-05,
      "loss": 0.0307,
      "step": 910
    },
    {
      "epoch": 0.368,
      "grad_norm": 0.3303394615650177,
      "learning_rate": 1.7549333333333335e-05,
      "loss": 0.025,
      "step": 920
    },
    {
      "epoch": 0.372,
      "grad_norm": 0.21746985614299774,
      "learning_rate": 1.7522666666666667e-05,
      "loss": 0.0228,
      "step": 930
    },
    {
      "epoch": 0.376,
      "grad_norm": 0.5872354507446289,
      "learning_rate": 1.7496000000000003e-05,
      "loss": 0.017,
      "step": 940
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.15210500359535217,
      "learning_rate": 1.7469333333333332e-05,
      "loss": 0.0085,
      "step": 950
    },
    {
      "epoch": 0.384,
      "grad_norm": 0.042600855231285095,
      "learning_rate": 1.7442666666666668e-05,
      "loss": 0.0203,
      "step": 960
    },
    {
      "epoch": 0.388,
      "grad_norm": 0.25781136751174927,
      "learning_rate": 1.7416e-05,
      "loss": 0.0157,
      "step": 970
    },
    {
      "epoch": 0.392,
      "grad_norm": 0.30370450019836426,
      "learning_rate": 1.7389333333333336e-05,
      "loss": 0.0123,
      "step": 980
    },
    {
      "epoch": 0.396,
      "grad_norm": 0.03196173533797264,
      "learning_rate": 1.736266666666667e-05,
      "loss": 0.0225,
      "step": 990
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.2160873413085938,
      "learning_rate": 1.7336e-05,
      "loss": 0.017,
      "step": 1000
    },
    {
      "epoch": 0.404,
      "grad_norm": 0.46171894669532776,
      "learning_rate": 1.7309333333333337e-05,
      "loss": 0.0282,
      "step": 1010
    },
    {
      "epoch": 0.408,
      "grad_norm": 0.5881948471069336,
      "learning_rate": 1.7282666666666666e-05,
      "loss": 0.0216,
      "step": 1020
    },
    {
      "epoch": 0.412,
      "grad_norm": 0.880967378616333,
      "learning_rate": 1.7256000000000002e-05,
      "loss": 0.0332,
      "step": 1030
    },
    {
      "epoch": 0.416,
      "grad_norm": 0.6353261470794678,
      "learning_rate": 1.7229333333333335e-05,
      "loss": 0.0168,
      "step": 1040
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.2639026939868927,
      "learning_rate": 1.7202666666666667e-05,
      "loss": 0.0132,
      "step": 1050
    },
    {
      "epoch": 0.424,
      "grad_norm": 0.6434178948402405,
      "learning_rate": 1.7176000000000003e-05,
      "loss": 0.0267,
      "step": 1060
    },
    {
      "epoch": 0.428,
      "grad_norm": 0.4788561463356018,
      "learning_rate": 1.7149333333333335e-05,
      "loss": 0.0138,
      "step": 1070
    },
    {
      "epoch": 0.432,
      "grad_norm": 0.1616518497467041,
      "learning_rate": 1.7122666666666668e-05,
      "loss": 0.0218,
      "step": 1080
    },
    {
      "epoch": 0.436,
      "grad_norm": 0.738276481628418,
      "learning_rate": 1.7096e-05,
      "loss": 0.0242,
      "step": 1090
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.8101776838302612,
      "learning_rate": 1.7069333333333336e-05,
      "loss": 0.021,
      "step": 1100
    },
    {
      "epoch": 0.444,
      "grad_norm": 0.30334436893463135,
      "learning_rate": 1.704266666666667e-05,
      "loss": 0.0155,
      "step": 1110
    },
    {
      "epoch": 0.448,
      "grad_norm": 0.5850915312767029,
      "learning_rate": 1.7016e-05,
      "loss": 0.017,
      "step": 1120
    },
    {
      "epoch": 0.452,
      "grad_norm": 0.5853003263473511,
      "learning_rate": 1.6989333333333337e-05,
      "loss": 0.0136,
      "step": 1130
    },
    {
      "epoch": 0.456,
      "grad_norm": 0.2730029821395874,
      "learning_rate": 1.6962666666666666e-05,
      "loss": 0.0243,
      "step": 1140
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.4739186763763428,
      "learning_rate": 1.6936000000000002e-05,
      "loss": 0.0157,
      "step": 1150
    },
    {
      "epoch": 0.464,
      "grad_norm": 0.10629147291183472,
      "learning_rate": 1.6909333333333334e-05,
      "loss": 0.0124,
      "step": 1160
    },
    {
      "epoch": 0.468,
      "grad_norm": 0.790368378162384,
      "learning_rate": 1.6882666666666667e-05,
      "loss": 0.0159,
      "step": 1170
    },
    {
      "epoch": 0.472,
      "grad_norm": 0.31718069314956665,
      "learning_rate": 1.6856000000000003e-05,
      "loss": 0.0133,
      "step": 1180
    },
    {
      "epoch": 0.476,
      "grad_norm": 0.48563238978385925,
      "learning_rate": 1.6829333333333335e-05,
      "loss": 0.0123,
      "step": 1190
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.8944634199142456,
      "learning_rate": 1.6802666666666668e-05,
      "loss": 0.0292,
      "step": 1200
    },
    {
      "epoch": 0.484,
      "grad_norm": 0.2670347988605499,
      "learning_rate": 1.6776e-05,
      "loss": 0.0168,
      "step": 1210
    },
    {
      "epoch": 0.488,
      "grad_norm": 1.2994669675827026,
      "learning_rate": 1.6749333333333336e-05,
      "loss": 0.0167,
      "step": 1220
    },
    {
      "epoch": 0.492,
      "grad_norm": 0.30467987060546875,
      "learning_rate": 1.6722666666666668e-05,
      "loss": 0.0206,
      "step": 1230
    },
    {
      "epoch": 0.496,
      "grad_norm": 0.6197196245193481,
      "learning_rate": 1.6696e-05,
      "loss": 0.0221,
      "step": 1240
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.4637460708618164,
      "learning_rate": 1.6669333333333337e-05,
      "loss": 0.0155,
      "step": 1250
    },
    {
      "epoch": 0.504,
      "grad_norm": 0.45008209347724915,
      "learning_rate": 1.6642666666666666e-05,
      "loss": 0.0113,
      "step": 1260
    },
    {
      "epoch": 0.508,
      "grad_norm": 0.37699171900749207,
      "learning_rate": 1.6616e-05,
      "loss": 0.0095,
      "step": 1270
    },
    {
      "epoch": 0.512,
      "grad_norm": 0.15619264543056488,
      "learning_rate": 1.6589333333333334e-05,
      "loss": 0.0304,
      "step": 1280
    },
    {
      "epoch": 0.516,
      "grad_norm": 0.14399205148220062,
      "learning_rate": 1.656266666666667e-05,
      "loss": 0.0105,
      "step": 1290
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.035384710878133774,
      "learning_rate": 1.6536000000000002e-05,
      "loss": 0.0172,
      "step": 1300
    },
    {
      "epoch": 0.524,
      "grad_norm": 0.40560394525527954,
      "learning_rate": 1.6509333333333335e-05,
      "loss": 0.0251,
      "step": 1310
    },
    {
      "epoch": 0.528,
      "grad_norm": 0.511066734790802,
      "learning_rate": 1.648266666666667e-05,
      "loss": 0.0099,
      "step": 1320
    },
    {
      "epoch": 0.532,
      "grad_norm": 0.4387587904930115,
      "learning_rate": 1.6456e-05,
      "loss": 0.0349,
      "step": 1330
    },
    {
      "epoch": 0.536,
      "grad_norm": 0.0479988232254982,
      "learning_rate": 1.6429333333333336e-05,
      "loss": 0.0147,
      "step": 1340
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.009533405303955,
      "learning_rate": 1.6402666666666668e-05,
      "loss": 0.0139,
      "step": 1350
    },
    {
      "epoch": 0.544,
      "grad_norm": 0.22427213191986084,
      "learning_rate": 1.6376e-05,
      "loss": 0.0128,
      "step": 1360
    },
    {
      "epoch": 0.548,
      "grad_norm": 1.3538604974746704,
      "learning_rate": 1.6349333333333336e-05,
      "loss": 0.0176,
      "step": 1370
    },
    {
      "epoch": 0.552,
      "grad_norm": 0.30630019307136536,
      "learning_rate": 1.632266666666667e-05,
      "loss": 0.0114,
      "step": 1380
    },
    {
      "epoch": 0.556,
      "grad_norm": 0.03086884692311287,
      "learning_rate": 1.6296e-05,
      "loss": 0.0142,
      "step": 1390
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.0927780270576477,
      "learning_rate": 1.6269333333333334e-05,
      "loss": 0.0146,
      "step": 1400
    },
    {
      "epoch": 0.564,
      "grad_norm": 0.5078845024108887,
      "learning_rate": 1.624266666666667e-05,
      "loss": 0.0207,
      "step": 1410
    },
    {
      "epoch": 0.568,
      "grad_norm": 0.098701611161232,
      "learning_rate": 1.6216000000000002e-05,
      "loss": 0.0166,
      "step": 1420
    },
    {
      "epoch": 0.572,
      "grad_norm": 0.3367624878883362,
      "learning_rate": 1.6189333333333334e-05,
      "loss": 0.0133,
      "step": 1430
    },
    {
      "epoch": 0.576,
      "grad_norm": 0.9793190360069275,
      "learning_rate": 1.616266666666667e-05,
      "loss": 0.024,
      "step": 1440
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.33047378063201904,
      "learning_rate": 1.6136e-05,
      "loss": 0.0204,
      "step": 1450
    },
    {
      "epoch": 0.584,
      "grad_norm": 0.34173500537872314,
      "learning_rate": 1.6109333333333335e-05,
      "loss": 0.0183,
      "step": 1460
    },
    {
      "epoch": 0.588,
      "grad_norm": 1.1207594871520996,
      "learning_rate": 1.6082666666666668e-05,
      "loss": 0.0311,
      "step": 1470
    },
    {
      "epoch": 0.592,
      "grad_norm": 0.291238933801651,
      "learning_rate": 1.6056e-05,
      "loss": 0.0178,
      "step": 1480
    },
    {
      "epoch": 0.596,
      "grad_norm": 0.04068385809659958,
      "learning_rate": 1.6029333333333336e-05,
      "loss": 0.0251,
      "step": 1490
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.6265895962715149,
      "learning_rate": 1.600266666666667e-05,
      "loss": 0.0194,
      "step": 1500
    },
    {
      "epoch": 0.604,
      "grad_norm": 0.2681906521320343,
      "learning_rate": 1.5976e-05,
      "loss": 0.024,
      "step": 1510
    },
    {
      "epoch": 0.608,
      "grad_norm": 0.5605235695838928,
      "learning_rate": 1.5949333333333333e-05,
      "loss": 0.0214,
      "step": 1520
    },
    {
      "epoch": 0.612,
      "grad_norm": 0.311605840921402,
      "learning_rate": 1.592266666666667e-05,
      "loss": 0.0224,
      "step": 1530
    },
    {
      "epoch": 0.616,
      "grad_norm": 0.09687894582748413,
      "learning_rate": 1.5896e-05,
      "loss": 0.0188,
      "step": 1540
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.04724609851837158,
      "learning_rate": 1.5869333333333334e-05,
      "loss": 0.0152,
      "step": 1550
    },
    {
      "epoch": 0.624,
      "grad_norm": 0.977717399597168,
      "learning_rate": 1.584266666666667e-05,
      "loss": 0.0149,
      "step": 1560
    },
    {
      "epoch": 0.628,
      "grad_norm": 0.2045346051454544,
      "learning_rate": 1.5816e-05,
      "loss": 0.0141,
      "step": 1570
    },
    {
      "epoch": 0.632,
      "grad_norm": 0.9844516515731812,
      "learning_rate": 1.5789333333333335e-05,
      "loss": 0.0192,
      "step": 1580
    },
    {
      "epoch": 0.636,
      "grad_norm": 0.34510698914527893,
      "learning_rate": 1.5762666666666667e-05,
      "loss": 0.0162,
      "step": 1590
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.13358092308044434,
      "learning_rate": 1.5736000000000003e-05,
      "loss": 0.0154,
      "step": 1600
    },
    {
      "epoch": 0.644,
      "grad_norm": 2.5463571548461914,
      "learning_rate": 1.5709333333333336e-05,
      "loss": 0.0221,
      "step": 1610
    },
    {
      "epoch": 0.648,
      "grad_norm": 0.8569863438606262,
      "learning_rate": 1.5682666666666668e-05,
      "loss": 0.0182,
      "step": 1620
    },
    {
      "epoch": 0.652,
      "grad_norm": 0.12949153780937195,
      "learning_rate": 1.5656000000000004e-05,
      "loss": 0.0235,
      "step": 1630
    },
    {
      "epoch": 0.656,
      "grad_norm": 0.06548243016004562,
      "learning_rate": 1.5629333333333333e-05,
      "loss": 0.0163,
      "step": 1640
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.09056022018194199,
      "learning_rate": 1.560266666666667e-05,
      "loss": 0.0098,
      "step": 1650
    },
    {
      "epoch": 0.664,
      "grad_norm": 0.5092670917510986,
      "learning_rate": 1.5576e-05,
      "loss": 0.0079,
      "step": 1660
    },
    {
      "epoch": 0.668,
      "grad_norm": 0.5560867190361023,
      "learning_rate": 1.5549333333333334e-05,
      "loss": 0.0754,
      "step": 1670
    },
    {
      "epoch": 0.672,
      "grad_norm": 0.6598222255706787,
      "learning_rate": 1.552266666666667e-05,
      "loss": 0.0086,
      "step": 1680
    },
    {
      "epoch": 0.676,
      "grad_norm": 0.2903485894203186,
      "learning_rate": 1.5496000000000002e-05,
      "loss": 0.0136,
      "step": 1690
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.35356321930885315,
      "learning_rate": 1.5469333333333335e-05,
      "loss": 0.0161,
      "step": 1700
    },
    {
      "epoch": 0.684,
      "grad_norm": 0.5022814273834229,
      "learning_rate": 1.5442666666666667e-05,
      "loss": 0.0066,
      "step": 1710
    },
    {
      "epoch": 0.688,
      "grad_norm": 0.44077223539352417,
      "learning_rate": 1.5416000000000003e-05,
      "loss": 0.0113,
      "step": 1720
    },
    {
      "epoch": 0.692,
      "grad_norm": 0.3408038020133972,
      "learning_rate": 1.5389333333333335e-05,
      "loss": 0.0157,
      "step": 1730
    },
    {
      "epoch": 0.696,
      "grad_norm": 0.598323404788971,
      "learning_rate": 1.5362666666666668e-05,
      "loss": 0.0305,
      "step": 1740
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.4936780333518982,
      "learning_rate": 1.5336000000000004e-05,
      "loss": 0.0156,
      "step": 1750
    },
    {
      "epoch": 0.704,
      "grad_norm": 0.14949312806129456,
      "learning_rate": 1.5309333333333333e-05,
      "loss": 0.0204,
      "step": 1760
    },
    {
      "epoch": 0.708,
      "grad_norm": 0.8175060153007507,
      "learning_rate": 1.528266666666667e-05,
      "loss": 0.01,
      "step": 1770
    },
    {
      "epoch": 0.712,
      "grad_norm": 0.7899267077445984,
      "learning_rate": 1.5256000000000003e-05,
      "loss": 0.0158,
      "step": 1780
    },
    {
      "epoch": 0.716,
      "grad_norm": 0.45237618684768677,
      "learning_rate": 1.5229333333333333e-05,
      "loss": 0.0085,
      "step": 1790
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.8656577467918396,
      "learning_rate": 1.5202666666666668e-05,
      "loss": 0.0181,
      "step": 1800
    },
    {
      "epoch": 0.724,
      "grad_norm": 0.5342351794242859,
      "learning_rate": 1.5176000000000002e-05,
      "loss": 0.0143,
      "step": 1810
    },
    {
      "epoch": 0.728,
      "grad_norm": 0.4299037456512451,
      "learning_rate": 1.5149333333333334e-05,
      "loss": 0.0207,
      "step": 1820
    },
    {
      "epoch": 0.732,
      "grad_norm": 0.3245934545993805,
      "learning_rate": 1.5122666666666668e-05,
      "loss": 0.0156,
      "step": 1830
    },
    {
      "epoch": 0.736,
      "grad_norm": 0.49418774247169495,
      "learning_rate": 1.5096000000000003e-05,
      "loss": 0.0177,
      "step": 1840
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.011599240824580193,
      "learning_rate": 1.5069333333333333e-05,
      "loss": 0.0075,
      "step": 1850
    },
    {
      "epoch": 0.744,
      "grad_norm": 0.7898696660995483,
      "learning_rate": 1.5042666666666667e-05,
      "loss": 0.0254,
      "step": 1860
    },
    {
      "epoch": 0.748,
      "grad_norm": 0.046382125467061996,
      "learning_rate": 1.5016000000000002e-05,
      "loss": 0.0155,
      "step": 1870
    },
    {
      "epoch": 0.752,
      "grad_norm": 0.686502993106842,
      "learning_rate": 1.4989333333333334e-05,
      "loss": 0.0151,
      "step": 1880
    },
    {
      "epoch": 0.756,
      "grad_norm": 0.29111289978027344,
      "learning_rate": 1.4962666666666668e-05,
      "loss": 0.01,
      "step": 1890
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.2389867901802063,
      "learning_rate": 1.4936000000000002e-05,
      "loss": 0.0133,
      "step": 1900
    },
    {
      "epoch": 0.764,
      "grad_norm": 0.5418954491615295,
      "learning_rate": 1.4909333333333337e-05,
      "loss": 0.0099,
      "step": 1910
    },
    {
      "epoch": 0.768,
      "grad_norm": 0.6589868664741516,
      "learning_rate": 1.4882666666666667e-05,
      "loss": 0.022,
      "step": 1920
    },
    {
      "epoch": 0.772,
      "grad_norm": 0.5248086452484131,
      "learning_rate": 1.4856000000000001e-05,
      "loss": 0.0219,
      "step": 1930
    },
    {
      "epoch": 0.776,
      "grad_norm": 0.22469958662986755,
      "learning_rate": 1.4829333333333336e-05,
      "loss": 0.0188,
      "step": 1940
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.39171817898750305,
      "learning_rate": 1.4802666666666668e-05,
      "loss": 0.0298,
      "step": 1950
    },
    {
      "epoch": 0.784,
      "grad_norm": 0.19769315421581268,
      "learning_rate": 1.4776000000000002e-05,
      "loss": 0.0269,
      "step": 1960
    },
    {
      "epoch": 0.788,
      "grad_norm": 0.09119541198015213,
      "learning_rate": 1.4749333333333336e-05,
      "loss": 0.009,
      "step": 1970
    },
    {
      "epoch": 0.792,
      "grad_norm": 0.7776653170585632,
      "learning_rate": 1.4722666666666667e-05,
      "loss": 0.0302,
      "step": 1980
    },
    {
      "epoch": 0.796,
      "grad_norm": 0.5470284223556519,
      "learning_rate": 1.4696000000000001e-05,
      "loss": 0.0134,
      "step": 1990
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.1767723560333252,
      "learning_rate": 1.4669333333333335e-05,
      "loss": 0.0158,
      "step": 2000
    },
    {
      "epoch": 0.804,
      "grad_norm": 1.0458197593688965,
      "learning_rate": 1.4642666666666668e-05,
      "loss": 0.0091,
      "step": 2010
    },
    {
      "epoch": 0.808,
      "grad_norm": 0.20710693299770355,
      "learning_rate": 1.4616000000000002e-05,
      "loss": 0.0156,
      "step": 2020
    },
    {
      "epoch": 0.812,
      "grad_norm": 0.39312994480133057,
      "learning_rate": 1.4589333333333336e-05,
      "loss": 0.0088,
      "step": 2030
    },
    {
      "epoch": 0.816,
      "grad_norm": 0.29199129343032837,
      "learning_rate": 1.4562666666666667e-05,
      "loss": 0.0084,
      "step": 2040
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.09144460409879684,
      "learning_rate": 1.4536000000000001e-05,
      "loss": 0.0104,
      "step": 2050
    },
    {
      "epoch": 0.824,
      "grad_norm": 0.1979495882987976,
      "learning_rate": 1.4509333333333335e-05,
      "loss": 0.0069,
      "step": 2060
    },
    {
      "epoch": 0.828,
      "grad_norm": 0.09715748578310013,
      "learning_rate": 1.4482666666666668e-05,
      "loss": 0.0134,
      "step": 2070
    },
    {
      "epoch": 0.832,
      "grad_norm": 0.44335874915122986,
      "learning_rate": 1.4456000000000002e-05,
      "loss": 0.0111,
      "step": 2080
    },
    {
      "epoch": 0.836,
      "grad_norm": 0.23245318233966827,
      "learning_rate": 1.4429333333333336e-05,
      "loss": 0.0074,
      "step": 2090
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.1386784315109253,
      "learning_rate": 1.4402666666666667e-05,
      "loss": 0.0208,
      "step": 2100
    },
    {
      "epoch": 0.844,
      "grad_norm": 0.14317528903484344,
      "learning_rate": 1.4376000000000001e-05,
      "loss": 0.0091,
      "step": 2110
    },
    {
      "epoch": 0.848,
      "grad_norm": 0.7507699728012085,
      "learning_rate": 1.4349333333333335e-05,
      "loss": 0.009,
      "step": 2120
    },
    {
      "epoch": 0.852,
      "grad_norm": 0.6268495321273804,
      "learning_rate": 1.4322666666666668e-05,
      "loss": 0.02,
      "step": 2130
    },
    {
      "epoch": 0.856,
      "grad_norm": 0.22086739540100098,
      "learning_rate": 1.4296000000000002e-05,
      "loss": 0.0107,
      "step": 2140
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.07895425707101822,
      "learning_rate": 1.4269333333333336e-05,
      "loss": 0.0188,
      "step": 2150
    },
    {
      "epoch": 0.864,
      "grad_norm": 0.21416853368282318,
      "learning_rate": 1.4242666666666667e-05,
      "loss": 0.0221,
      "step": 2160
    },
    {
      "epoch": 0.868,
      "grad_norm": 1.2145147323608398,
      "learning_rate": 1.4216e-05,
      "loss": 0.0203,
      "step": 2170
    },
    {
      "epoch": 0.872,
      "grad_norm": 0.05001137778162956,
      "learning_rate": 1.4189333333333335e-05,
      "loss": 0.006,
      "step": 2180
    },
    {
      "epoch": 0.876,
      "grad_norm": 0.13904140889644623,
      "learning_rate": 1.4162666666666667e-05,
      "loss": 0.0151,
      "step": 2190
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.4055861532688141,
      "learning_rate": 1.4136000000000002e-05,
      "loss": 0.0124,
      "step": 2200
    },
    {
      "epoch": 0.884,
      "grad_norm": 0.9925926327705383,
      "learning_rate": 1.4109333333333336e-05,
      "loss": 0.0124,
      "step": 2210
    },
    {
      "epoch": 0.888,
      "grad_norm": 0.7202563285827637,
      "learning_rate": 1.4082666666666668e-05,
      "loss": 0.0157,
      "step": 2220
    },
    {
      "epoch": 0.892,
      "grad_norm": 0.2726239264011383,
      "learning_rate": 1.4056e-05,
      "loss": 0.0125,
      "step": 2230
    },
    {
      "epoch": 0.896,
      "grad_norm": 0.10241971909999847,
      "learning_rate": 1.4029333333333335e-05,
      "loss": 0.0054,
      "step": 2240
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.4274355471134186,
      "learning_rate": 1.4002666666666669e-05,
      "loss": 0.0415,
      "step": 2250
    },
    {
      "epoch": 0.904,
      "grad_norm": 0.7525640726089478,
      "learning_rate": 1.3976000000000001e-05,
      "loss": 0.0056,
      "step": 2260
    },
    {
      "epoch": 0.908,
      "grad_norm": 0.020948464050889015,
      "learning_rate": 1.3949333333333336e-05,
      "loss": 0.0123,
      "step": 2270
    },
    {
      "epoch": 0.912,
      "grad_norm": 0.10714758932590485,
      "learning_rate": 1.3922666666666668e-05,
      "loss": 0.0056,
      "step": 2280
    },
    {
      "epoch": 0.916,
      "grad_norm": 0.015472405590116978,
      "learning_rate": 1.3896e-05,
      "loss": 0.0056,
      "step": 2290
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.2519419193267822,
      "learning_rate": 1.3869333333333335e-05,
      "loss": 0.031,
      "step": 2300
    },
    {
      "epoch": 0.924,
      "grad_norm": 0.16645309329032898,
      "learning_rate": 1.3842666666666669e-05,
      "loss": 0.0114,
      "step": 2310
    },
    {
      "epoch": 0.928,
      "grad_norm": 0.4439389407634735,
      "learning_rate": 1.3816000000000001e-05,
      "loss": 0.0064,
      "step": 2320
    },
    {
      "epoch": 0.932,
      "grad_norm": 0.34994086623191833,
      "learning_rate": 1.3789333333333335e-05,
      "loss": 0.0167,
      "step": 2330
    },
    {
      "epoch": 0.936,
      "grad_norm": 0.12434075772762299,
      "learning_rate": 1.3762666666666668e-05,
      "loss": 0.0123,
      "step": 2340
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.13906121253967285,
      "learning_rate": 1.3736e-05,
      "loss": 0.0163,
      "step": 2350
    },
    {
      "epoch": 0.944,
      "grad_norm": 0.042402829974889755,
      "learning_rate": 1.3709333333333334e-05,
      "loss": 0.0094,
      "step": 2360
    },
    {
      "epoch": 0.948,
      "grad_norm": 0.03661739081144333,
      "learning_rate": 1.3682666666666669e-05,
      "loss": 0.017,
      "step": 2370
    },
    {
      "epoch": 0.952,
      "grad_norm": 1.1860477924346924,
      "learning_rate": 1.3656000000000001e-05,
      "loss": 0.0157,
      "step": 2380
    },
    {
      "epoch": 0.956,
      "grad_norm": 0.4261334240436554,
      "learning_rate": 1.3629333333333335e-05,
      "loss": 0.0061,
      "step": 2390
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.032894380390644073,
      "learning_rate": 1.3602666666666668e-05,
      "loss": 0.0066,
      "step": 2400
    },
    {
      "epoch": 0.964,
      "grad_norm": 0.26576825976371765,
      "learning_rate": 1.3576e-05,
      "loss": 0.0094,
      "step": 2410
    },
    {
      "epoch": 0.968,
      "grad_norm": 1.8794046640396118,
      "learning_rate": 1.3549333333333334e-05,
      "loss": 0.0188,
      "step": 2420
    },
    {
      "epoch": 0.972,
      "grad_norm": 0.33597004413604736,
      "learning_rate": 1.3522666666666668e-05,
      "loss": 0.0113,
      "step": 2430
    },
    {
      "epoch": 0.976,
      "grad_norm": 0.38570621609687805,
      "learning_rate": 1.3496000000000001e-05,
      "loss": 0.0206,
      "step": 2440
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.04347451403737068,
      "learning_rate": 1.3469333333333335e-05,
      "loss": 0.0131,
      "step": 2450
    },
    {
      "epoch": 0.984,
      "grad_norm": 0.3343929052352905,
      "learning_rate": 1.3442666666666668e-05,
      "loss": 0.0211,
      "step": 2460
    },
    {
      "epoch": 0.988,
      "grad_norm": 0.09174532443284988,
      "learning_rate": 1.3416e-05,
      "loss": 0.026,
      "step": 2470
    },
    {
      "epoch": 0.992,
      "grad_norm": 0.39619389176368713,
      "learning_rate": 1.3389333333333334e-05,
      "loss": 0.0259,
      "step": 2480
    },
    {
      "epoch": 0.996,
      "grad_norm": 0.13521726429462433,
      "learning_rate": 1.3362666666666668e-05,
      "loss": 0.0146,
      "step": 2490
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.8210729360580444,
      "learning_rate": 1.3336e-05,
      "loss": 0.0281,
      "step": 2500
    },
    {
      "epoch": 1.004,
      "grad_norm": 0.102897047996521,
      "learning_rate": 1.3309333333333335e-05,
      "loss": 0.0111,
      "step": 2510
    },
    {
      "epoch": 1.008,
      "grad_norm": 0.025655673816800117,
      "learning_rate": 1.3282666666666667e-05,
      "loss": 0.0056,
      "step": 2520
    },
    {
      "epoch": 1.012,
      "grad_norm": 0.10394986718893051,
      "learning_rate": 1.3256e-05,
      "loss": 0.0039,
      "step": 2530
    },
    {
      "epoch": 1.016,
      "grad_norm": 0.02231503650546074,
      "learning_rate": 1.3229333333333334e-05,
      "loss": 0.0105,
      "step": 2540
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.031614866107702255,
      "learning_rate": 1.3202666666666668e-05,
      "loss": 0.0082,
      "step": 2550
    },
    {
      "epoch": 1.024,
      "grad_norm": 1.9688758850097656,
      "learning_rate": 1.3176000000000002e-05,
      "loss": 0.0076,
      "step": 2560
    },
    {
      "epoch": 1.028,
      "grad_norm": 0.16251401603221893,
      "learning_rate": 1.3149333333333335e-05,
      "loss": 0.0066,
      "step": 2570
    },
    {
      "epoch": 1.032,
      "grad_norm": 0.023923799395561218,
      "learning_rate": 1.3122666666666667e-05,
      "loss": 0.0049,
      "step": 2580
    },
    {
      "epoch": 1.036,
      "grad_norm": 0.20615023374557495,
      "learning_rate": 1.3096000000000001e-05,
      "loss": 0.0065,
      "step": 2590
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.030895987525582314,
      "learning_rate": 1.3069333333333334e-05,
      "loss": 0.0174,
      "step": 2600
    },
    {
      "epoch": 1.044,
      "grad_norm": 0.06426539272069931,
      "learning_rate": 1.3042666666666668e-05,
      "loss": 0.0039,
      "step": 2610
    },
    {
      "epoch": 1.048,
      "grad_norm": 0.2702430784702301,
      "learning_rate": 1.3016000000000002e-05,
      "loss": 0.0186,
      "step": 2620
    },
    {
      "epoch": 1.052,
      "grad_norm": 0.4533066153526306,
      "learning_rate": 1.2989333333333335e-05,
      "loss": 0.0038,
      "step": 2630
    },
    {
      "epoch": 1.056,
      "grad_norm": 0.003612367669120431,
      "learning_rate": 1.2962666666666667e-05,
      "loss": 0.0042,
      "step": 2640
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.8524851202964783,
      "learning_rate": 1.2936000000000001e-05,
      "loss": 0.0136,
      "step": 2650
    },
    {
      "epoch": 1.064,
      "grad_norm": 0.2159830927848816,
      "learning_rate": 1.2909333333333334e-05,
      "loss": 0.0071,
      "step": 2660
    },
    {
      "epoch": 1.068,
      "grad_norm": 0.26214301586151123,
      "learning_rate": 1.2882666666666668e-05,
      "loss": 0.0036,
      "step": 2670
    },
    {
      "epoch": 1.072,
      "grad_norm": 0.3037241995334625,
      "learning_rate": 1.2856000000000002e-05,
      "loss": 0.006,
      "step": 2680
    },
    {
      "epoch": 1.076,
      "grad_norm": 0.11315573006868362,
      "learning_rate": 1.2829333333333334e-05,
      "loss": 0.008,
      "step": 2690
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.9994543194770813,
      "learning_rate": 1.2802666666666667e-05,
      "loss": 0.0149,
      "step": 2700
    },
    {
      "epoch": 1.084,
      "grad_norm": 0.11175864934921265,
      "learning_rate": 1.2776000000000001e-05,
      "loss": 0.002,
      "step": 2710
    },
    {
      "epoch": 1.088,
      "grad_norm": 0.6378098130226135,
      "learning_rate": 1.2749333333333333e-05,
      "loss": 0.0056,
      "step": 2720
    },
    {
      "epoch": 1.092,
      "grad_norm": 0.25910165905952454,
      "learning_rate": 1.2722666666666668e-05,
      "loss": 0.009,
      "step": 2730
    },
    {
      "epoch": 1.096,
      "grad_norm": 0.13912245631217957,
      "learning_rate": 1.2696000000000002e-05,
      "loss": 0.0045,
      "step": 2740
    },
    {
      "epoch": 1.1,
      "grad_norm": 1.47628915309906,
      "learning_rate": 1.2669333333333334e-05,
      "loss": 0.0085,
      "step": 2750
    },
    {
      "epoch": 1.104,
      "grad_norm": 1.4722543954849243,
      "learning_rate": 1.2642666666666667e-05,
      "loss": 0.014,
      "step": 2760
    },
    {
      "epoch": 1.108,
      "grad_norm": 0.019619811326265335,
      "learning_rate": 1.2616e-05,
      "loss": 0.0056,
      "step": 2770
    },
    {
      "epoch": 1.112,
      "grad_norm": 0.1875801533460617,
      "learning_rate": 1.2589333333333333e-05,
      "loss": 0.0101,
      "step": 2780
    },
    {
      "epoch": 1.116,
      "grad_norm": 0.03496883064508438,
      "learning_rate": 1.2562666666666667e-05,
      "loss": 0.0064,
      "step": 2790
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.050390537828207016,
      "learning_rate": 1.2536000000000002e-05,
      "loss": 0.0073,
      "step": 2800
    },
    {
      "epoch": 1.124,
      "grad_norm": 0.04289994761347771,
      "learning_rate": 1.2509333333333334e-05,
      "loss": 0.01,
      "step": 2810
    },
    {
      "epoch": 1.1280000000000001,
      "grad_norm": 0.03887980803847313,
      "learning_rate": 1.2482666666666668e-05,
      "loss": 0.0068,
      "step": 2820
    },
    {
      "epoch": 1.1320000000000001,
      "grad_norm": 0.47530990839004517,
      "learning_rate": 1.2456e-05,
      "loss": 0.0085,
      "step": 2830
    },
    {
      "epoch": 1.1360000000000001,
      "grad_norm": 0.24559617042541504,
      "learning_rate": 1.2429333333333333e-05,
      "loss": 0.008,
      "step": 2840
    },
    {
      "epoch": 1.1400000000000001,
      "grad_norm": 0.8538888692855835,
      "learning_rate": 1.2402666666666667e-05,
      "loss": 0.0087,
      "step": 2850
    },
    {
      "epoch": 1.144,
      "grad_norm": 0.8702161908149719,
      "learning_rate": 1.2376000000000001e-05,
      "loss": 0.0063,
      "step": 2860
    },
    {
      "epoch": 1.148,
      "grad_norm": 0.09185875207185745,
      "learning_rate": 1.2349333333333336e-05,
      "loss": 0.008,
      "step": 2870
    },
    {
      "epoch": 1.152,
      "grad_norm": 0.07924222946166992,
      "learning_rate": 1.2322666666666668e-05,
      "loss": 0.0013,
      "step": 2880
    },
    {
      "epoch": 1.156,
      "grad_norm": 0.08505277335643768,
      "learning_rate": 1.2296e-05,
      "loss": 0.0064,
      "step": 2890
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.01135888509452343,
      "learning_rate": 1.2269333333333335e-05,
      "loss": 0.0123,
      "step": 2900
    },
    {
      "epoch": 1.164,
      "grad_norm": 0.34683528542518616,
      "learning_rate": 1.2242666666666667e-05,
      "loss": 0.0095,
      "step": 2910
    },
    {
      "epoch": 1.168,
      "grad_norm": 0.37993842363357544,
      "learning_rate": 1.2216000000000001e-05,
      "loss": 0.0154,
      "step": 2920
    },
    {
      "epoch": 1.172,
      "grad_norm": 0.057270925492048264,
      "learning_rate": 1.2189333333333335e-05,
      "loss": 0.0045,
      "step": 2930
    },
    {
      "epoch": 1.176,
      "grad_norm": 1.403596043586731,
      "learning_rate": 1.2162666666666668e-05,
      "loss": 0.0097,
      "step": 2940
    },
    {
      "epoch": 1.18,
      "grad_norm": 1.09833824634552,
      "learning_rate": 1.2136e-05,
      "loss": 0.0102,
      "step": 2950
    },
    {
      "epoch": 1.184,
      "grad_norm": 0.3991793990135193,
      "learning_rate": 1.2109333333333335e-05,
      "loss": 0.0044,
      "step": 2960
    },
    {
      "epoch": 1.188,
      "grad_norm": 0.24050942063331604,
      "learning_rate": 1.2082666666666667e-05,
      "loss": 0.0064,
      "step": 2970
    },
    {
      "epoch": 1.192,
      "grad_norm": 0.4356763958930969,
      "learning_rate": 1.2056000000000001e-05,
      "loss": 0.0035,
      "step": 2980
    },
    {
      "epoch": 1.196,
      "grad_norm": 0.049443766474723816,
      "learning_rate": 1.2029333333333335e-05,
      "loss": 0.005,
      "step": 2990
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.6603376865386963,
      "learning_rate": 1.2002666666666668e-05,
      "loss": 0.0103,
      "step": 3000
    },
    {
      "epoch": 1.204,
      "grad_norm": 0.03400076553225517,
      "learning_rate": 1.1976e-05,
      "loss": 0.0053,
      "step": 3010
    },
    {
      "epoch": 1.208,
      "grad_norm": 0.03800227493047714,
      "learning_rate": 1.1949333333333334e-05,
      "loss": 0.0086,
      "step": 3020
    },
    {
      "epoch": 1.212,
      "grad_norm": 0.1623457372188568,
      "learning_rate": 1.1922666666666667e-05,
      "loss": 0.0023,
      "step": 3030
    },
    {
      "epoch": 1.216,
      "grad_norm": 0.32221028208732605,
      "learning_rate": 1.1896000000000001e-05,
      "loss": 0.0125,
      "step": 3040
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.12755796313285828,
      "learning_rate": 1.1869333333333335e-05,
      "loss": 0.0185,
      "step": 3050
    },
    {
      "epoch": 1.224,
      "grad_norm": 0.6039956212043762,
      "learning_rate": 1.1842666666666668e-05,
      "loss": 0.0148,
      "step": 3060
    },
    {
      "epoch": 1.228,
      "grad_norm": 0.11121472716331482,
      "learning_rate": 1.1816e-05,
      "loss": 0.0056,
      "step": 3070
    },
    {
      "epoch": 1.232,
      "grad_norm": 0.1286097913980484,
      "learning_rate": 1.1789333333333334e-05,
      "loss": 0.0072,
      "step": 3080
    },
    {
      "epoch": 1.236,
      "grad_norm": 0.5666358470916748,
      "learning_rate": 1.1762666666666667e-05,
      "loss": 0.0059,
      "step": 3090
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.016139091923832893,
      "learning_rate": 1.1736e-05,
      "loss": 0.0154,
      "step": 3100
    },
    {
      "epoch": 1.244,
      "grad_norm": 0.2384842038154602,
      "learning_rate": 1.1709333333333335e-05,
      "loss": 0.0084,
      "step": 3110
    },
    {
      "epoch": 1.248,
      "grad_norm": 0.16955052316188812,
      "learning_rate": 1.1682666666666667e-05,
      "loss": 0.0044,
      "step": 3120
    },
    {
      "epoch": 1.252,
      "grad_norm": 0.15601089596748352,
      "learning_rate": 1.1656e-05,
      "loss": 0.0063,
      "step": 3130
    },
    {
      "epoch": 1.256,
      "grad_norm": 0.00668012211099267,
      "learning_rate": 1.1629333333333334e-05,
      "loss": 0.0078,
      "step": 3140
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.5479087829589844,
      "learning_rate": 1.1602666666666666e-05,
      "loss": 0.0117,
      "step": 3150
    },
    {
      "epoch": 1.264,
      "grad_norm": 0.013907099142670631,
      "learning_rate": 1.1576e-05,
      "loss": 0.0186,
      "step": 3160
    },
    {
      "epoch": 1.268,
      "grad_norm": 0.10586272180080414,
      "learning_rate": 1.1549333333333335e-05,
      "loss": 0.0051,
      "step": 3170
    },
    {
      "epoch": 1.272,
      "grad_norm": 0.09127075225114822,
      "learning_rate": 1.1522666666666669e-05,
      "loss": 0.0088,
      "step": 3180
    },
    {
      "epoch": 1.276,
      "grad_norm": 0.04465528577566147,
      "learning_rate": 1.1496e-05,
      "loss": 0.0076,
      "step": 3190
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.45048409700393677,
      "learning_rate": 1.1469333333333334e-05,
      "loss": 0.007,
      "step": 3200
    },
    {
      "epoch": 1.284,
      "grad_norm": 0.34967005252838135,
      "learning_rate": 1.1442666666666668e-05,
      "loss": 0.0109,
      "step": 3210
    },
    {
      "epoch": 1.288,
      "grad_norm": 0.1704198122024536,
      "learning_rate": 1.1416e-05,
      "loss": 0.0089,
      "step": 3220
    },
    {
      "epoch": 1.292,
      "grad_norm": 1.0317686796188354,
      "learning_rate": 1.1389333333333335e-05,
      "loss": 0.0054,
      "step": 3230
    },
    {
      "epoch": 1.296,
      "grad_norm": 0.7797104120254517,
      "learning_rate": 1.1362666666666669e-05,
      "loss": 0.0195,
      "step": 3240
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.07574804127216339,
      "learning_rate": 1.1336e-05,
      "loss": 0.014,
      "step": 3250
    },
    {
      "epoch": 1.304,
      "grad_norm": 0.15574993193149567,
      "learning_rate": 1.1309333333333334e-05,
      "loss": 0.0112,
      "step": 3260
    },
    {
      "epoch": 1.308,
      "grad_norm": 0.4264968931674957,
      "learning_rate": 1.1282666666666668e-05,
      "loss": 0.0164,
      "step": 3270
    },
    {
      "epoch": 1.312,
      "grad_norm": 0.23427623510360718,
      "learning_rate": 1.1256e-05,
      "loss": 0.0069,
      "step": 3280
    },
    {
      "epoch": 1.316,
      "grad_norm": 0.053191378712654114,
      "learning_rate": 1.1229333333333334e-05,
      "loss": 0.0047,
      "step": 3290
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.12808625400066376,
      "learning_rate": 1.1202666666666669e-05,
      "loss": 0.0078,
      "step": 3300
    },
    {
      "epoch": 1.324,
      "grad_norm": 0.16853442788124084,
      "learning_rate": 1.1176e-05,
      "loss": 0.017,
      "step": 3310
    },
    {
      "epoch": 1.328,
      "grad_norm": 0.11950560659170151,
      "learning_rate": 1.1149333333333334e-05,
      "loss": 0.0244,
      "step": 3320
    },
    {
      "epoch": 1.332,
      "grad_norm": 0.023982062935829163,
      "learning_rate": 1.1122666666666668e-05,
      "loss": 0.0119,
      "step": 3330
    },
    {
      "epoch": 1.336,
      "grad_norm": 0.19501851499080658,
      "learning_rate": 1.1096e-05,
      "loss": 0.0062,
      "step": 3340
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.027002785354852676,
      "learning_rate": 1.1069333333333334e-05,
      "loss": 0.0076,
      "step": 3350
    },
    {
      "epoch": 1.3439999999999999,
      "grad_norm": 0.07895784825086594,
      "learning_rate": 1.1042666666666668e-05,
      "loss": 0.0118,
      "step": 3360
    },
    {
      "epoch": 1.3479999999999999,
      "grad_norm": 0.37084221839904785,
      "learning_rate": 1.1016e-05,
      "loss": 0.0057,
      "step": 3370
    },
    {
      "epoch": 1.3519999999999999,
      "grad_norm": 0.2850044369697571,
      "learning_rate": 1.0989333333333333e-05,
      "loss": 0.0173,
      "step": 3380
    },
    {
      "epoch": 1.3559999999999999,
      "grad_norm": 0.08657296746969223,
      "learning_rate": 1.0962666666666668e-05,
      "loss": 0.0102,
      "step": 3390
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 0.28808775544166565,
      "learning_rate": 1.0936e-05,
      "loss": 0.0054,
      "step": 3400
    },
    {
      "epoch": 1.3639999999999999,
      "grad_norm": 0.010290145874023438,
      "learning_rate": 1.0909333333333334e-05,
      "loss": 0.0028,
      "step": 3410
    },
    {
      "epoch": 1.3679999999999999,
      "grad_norm": 0.06279267370700836,
      "learning_rate": 1.0882666666666668e-05,
      "loss": 0.0097,
      "step": 3420
    },
    {
      "epoch": 1.3719999999999999,
      "grad_norm": 0.012935275211930275,
      "learning_rate": 1.0855999999999999e-05,
      "loss": 0.0066,
      "step": 3430
    },
    {
      "epoch": 1.376,
      "grad_norm": 0.5250831246376038,
      "learning_rate": 1.0829333333333333e-05,
      "loss": 0.0143,
      "step": 3440
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.1211204081773758,
      "learning_rate": 1.0802666666666667e-05,
      "loss": 0.0075,
      "step": 3450
    },
    {
      "epoch": 1.384,
      "grad_norm": 0.45196980237960815,
      "learning_rate": 1.0776e-05,
      "loss": 0.0123,
      "step": 3460
    },
    {
      "epoch": 1.388,
      "grad_norm": 0.049536820501089096,
      "learning_rate": 1.0749333333333334e-05,
      "loss": 0.0029,
      "step": 3470
    },
    {
      "epoch": 1.392,
      "grad_norm": 2.252854824066162,
      "learning_rate": 1.0722666666666668e-05,
      "loss": 0.007,
      "step": 3480
    },
    {
      "epoch": 1.396,
      "grad_norm": 0.022227125242352486,
      "learning_rate": 1.0696000000000002e-05,
      "loss": 0.0059,
      "step": 3490
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.11081637442111969,
      "learning_rate": 1.0669333333333333e-05,
      "loss": 0.0114,
      "step": 3500
    },
    {
      "epoch": 1.404,
      "grad_norm": 0.0907924473285675,
      "learning_rate": 1.0642666666666667e-05,
      "loss": 0.0064,
      "step": 3510
    },
    {
      "epoch": 1.408,
      "grad_norm": 0.7220677733421326,
      "learning_rate": 1.0616000000000001e-05,
      "loss": 0.0052,
      "step": 3520
    },
    {
      "epoch": 1.412,
      "grad_norm": 0.12755504250526428,
      "learning_rate": 1.0589333333333334e-05,
      "loss": 0.0087,
      "step": 3530
    },
    {
      "epoch": 1.416,
      "grad_norm": 0.05636947974562645,
      "learning_rate": 1.0562666666666668e-05,
      "loss": 0.0049,
      "step": 3540
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.16365782916545868,
      "learning_rate": 1.0536000000000002e-05,
      "loss": 0.0108,
      "step": 3550
    },
    {
      "epoch": 1.424,
      "grad_norm": 0.3844723105430603,
      "learning_rate": 1.0509333333333333e-05,
      "loss": 0.004,
      "step": 3560
    },
    {
      "epoch": 1.428,
      "grad_norm": 0.08439529687166214,
      "learning_rate": 1.0482666666666667e-05,
      "loss": 0.0022,
      "step": 3570
    },
    {
      "epoch": 1.432,
      "grad_norm": 0.8797373175621033,
      "learning_rate": 1.0456000000000001e-05,
      "loss": 0.008,
      "step": 3580
    },
    {
      "epoch": 1.436,
      "grad_norm": 0.07901184260845184,
      "learning_rate": 1.0429333333333334e-05,
      "loss": 0.0052,
      "step": 3590
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.8268889784812927,
      "learning_rate": 1.0402666666666668e-05,
      "loss": 0.0138,
      "step": 3600
    },
    {
      "epoch": 1.444,
      "grad_norm": 0.051826488226652145,
      "learning_rate": 1.0376000000000002e-05,
      "loss": 0.0037,
      "step": 3610
    },
    {
      "epoch": 1.448,
      "grad_norm": 0.0373123399913311,
      "learning_rate": 1.0349333333333333e-05,
      "loss": 0.0072,
      "step": 3620
    },
    {
      "epoch": 1.452,
      "grad_norm": 0.2756941318511963,
      "learning_rate": 1.0322666666666667e-05,
      "loss": 0.01,
      "step": 3630
    },
    {
      "epoch": 1.456,
      "grad_norm": 0.010224858298897743,
      "learning_rate": 1.0296000000000001e-05,
      "loss": 0.0078,
      "step": 3640
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.932050883769989,
      "learning_rate": 1.0269333333333333e-05,
      "loss": 0.0065,
      "step": 3650
    },
    {
      "epoch": 1.464,
      "grad_norm": 0.16456906497478485,
      "learning_rate": 1.0242666666666668e-05,
      "loss": 0.0096,
      "step": 3660
    },
    {
      "epoch": 1.468,
      "grad_norm": 0.010340665467083454,
      "learning_rate": 1.0216000000000002e-05,
      "loss": 0.0046,
      "step": 3670
    },
    {
      "epoch": 1.472,
      "grad_norm": 0.06497020274400711,
      "learning_rate": 1.0189333333333333e-05,
      "loss": 0.0052,
      "step": 3680
    },
    {
      "epoch": 1.476,
      "grad_norm": 0.11903420090675354,
      "learning_rate": 1.0162666666666667e-05,
      "loss": 0.0261,
      "step": 3690
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.1704036146402359,
      "learning_rate": 1.0136000000000001e-05,
      "loss": 0.0048,
      "step": 3700
    },
    {
      "epoch": 1.484,
      "grad_norm": 0.1093859076499939,
      "learning_rate": 1.0109333333333333e-05,
      "loss": 0.0092,
      "step": 3710
    },
    {
      "epoch": 1.488,
      "grad_norm": 0.11268503963947296,
      "learning_rate": 1.0082666666666667e-05,
      "loss": 0.0115,
      "step": 3720
    },
    {
      "epoch": 1.492,
      "grad_norm": 0.025568125769495964,
      "learning_rate": 1.0056000000000002e-05,
      "loss": 0.0086,
      "step": 3730
    },
    {
      "epoch": 1.496,
      "grad_norm": 0.11684876680374146,
      "learning_rate": 1.0029333333333332e-05,
      "loss": 0.004,
      "step": 3740
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.249797523021698,
      "learning_rate": 1.0002666666666667e-05,
      "loss": 0.0038,
      "step": 3750
    },
    {
      "epoch": 1.504,
      "grad_norm": 0.15195436775684357,
      "learning_rate": 9.976e-06,
      "loss": 0.0088,
      "step": 3760
    },
    {
      "epoch": 1.508,
      "grad_norm": 0.06799100339412689,
      "learning_rate": 9.949333333333335e-06,
      "loss": 0.0039,
      "step": 3770
    },
    {
      "epoch": 1.512,
      "grad_norm": 0.5076122879981995,
      "learning_rate": 9.922666666666667e-06,
      "loss": 0.0053,
      "step": 3780
    },
    {
      "epoch": 1.516,
      "grad_norm": 0.39406153559684753,
      "learning_rate": 9.896000000000001e-06,
      "loss": 0.0048,
      "step": 3790
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.05492185801267624,
      "learning_rate": 9.869333333333334e-06,
      "loss": 0.0075,
      "step": 3800
    },
    {
      "epoch": 1.524,
      "grad_norm": 0.036349423229694366,
      "learning_rate": 9.842666666666666e-06,
      "loss": 0.008,
      "step": 3810
    },
    {
      "epoch": 1.528,
      "grad_norm": 0.21978576481342316,
      "learning_rate": 9.816e-06,
      "loss": 0.0104,
      "step": 3820
    },
    {
      "epoch": 1.532,
      "grad_norm": 2.191333055496216,
      "learning_rate": 9.789333333333335e-06,
      "loss": 0.0116,
      "step": 3830
    },
    {
      "epoch": 1.536,
      "grad_norm": 0.07388892769813538,
      "learning_rate": 9.762666666666667e-06,
      "loss": 0.0047,
      "step": 3840
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.05516854673624039,
      "learning_rate": 9.736000000000001e-06,
      "loss": 0.0067,
      "step": 3850
    },
    {
      "epoch": 1.544,
      "grad_norm": 0.05010232329368591,
      "learning_rate": 9.709333333333334e-06,
      "loss": 0.0083,
      "step": 3860
    },
    {
      "epoch": 1.548,
      "grad_norm": 0.014501885510981083,
      "learning_rate": 9.682666666666668e-06,
      "loss": 0.0054,
      "step": 3870
    },
    {
      "epoch": 1.552,
      "grad_norm": 0.03931400924921036,
      "learning_rate": 9.656e-06,
      "loss": 0.0044,
      "step": 3880
    },
    {
      "epoch": 1.556,
      "grad_norm": 0.9710586667060852,
      "learning_rate": 9.629333333333335e-06,
      "loss": 0.0112,
      "step": 3890
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.03193158283829689,
      "learning_rate": 9.602666666666669e-06,
      "loss": 0.0064,
      "step": 3900
    },
    {
      "epoch": 1.564,
      "grad_norm": 0.6841661930084229,
      "learning_rate": 9.576000000000001e-06,
      "loss": 0.0096,
      "step": 3910
    },
    {
      "epoch": 1.568,
      "grad_norm": 0.7904579639434814,
      "learning_rate": 9.549333333333334e-06,
      "loss": 0.0185,
      "step": 3920
    },
    {
      "epoch": 1.572,
      "grad_norm": 0.05860750749707222,
      "learning_rate": 9.522666666666668e-06,
      "loss": 0.0064,
      "step": 3930
    },
    {
      "epoch": 1.576,
      "grad_norm": 0.6004430055618286,
      "learning_rate": 9.496e-06,
      "loss": 0.0078,
      "step": 3940
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.2935645282268524,
      "learning_rate": 9.469333333333334e-06,
      "loss": 0.0054,
      "step": 3950
    },
    {
      "epoch": 1.584,
      "grad_norm": 0.634563684463501,
      "learning_rate": 9.442666666666669e-06,
      "loss": 0.0146,
      "step": 3960
    },
    {
      "epoch": 1.588,
      "grad_norm": 2.009648323059082,
      "learning_rate": 9.416000000000001e-06,
      "loss": 0.0092,
      "step": 3970
    },
    {
      "epoch": 1.592,
      "grad_norm": 0.0445108488202095,
      "learning_rate": 9.389333333333333e-06,
      "loss": 0.0038,
      "step": 3980
    },
    {
      "epoch": 1.596,
      "grad_norm": 0.5644977688789368,
      "learning_rate": 9.362666666666668e-06,
      "loss": 0.005,
      "step": 3990
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.9463549256324768,
      "learning_rate": 9.336e-06,
      "loss": 0.0069,
      "step": 4000
    },
    {
      "epoch": 1.604,
      "grad_norm": 0.29927629232406616,
      "learning_rate": 9.309333333333334e-06,
      "loss": 0.012,
      "step": 4010
    },
    {
      "epoch": 1.608,
      "grad_norm": 0.4793705344200134,
      "learning_rate": 9.282666666666668e-06,
      "loss": 0.005,
      "step": 4020
    },
    {
      "epoch": 1.612,
      "grad_norm": 0.9023504257202148,
      "learning_rate": 9.256e-06,
      "loss": 0.0099,
      "step": 4030
    },
    {
      "epoch": 1.616,
      "grad_norm": 0.2935210168361664,
      "learning_rate": 9.229333333333335e-06,
      "loss": 0.007,
      "step": 4040
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.020241528749465942,
      "learning_rate": 9.202666666666667e-06,
      "loss": 0.0039,
      "step": 4050
    },
    {
      "epoch": 1.624,
      "grad_norm": 0.8175525069236755,
      "learning_rate": 9.176e-06,
      "loss": 0.004,
      "step": 4060
    },
    {
      "epoch": 1.6280000000000001,
      "grad_norm": 0.09615462273359299,
      "learning_rate": 9.149333333333334e-06,
      "loss": 0.0022,
      "step": 4070
    },
    {
      "epoch": 1.6320000000000001,
      "grad_norm": 0.01700746826827526,
      "learning_rate": 9.122666666666668e-06,
      "loss": 0.0042,
      "step": 4080
    },
    {
      "epoch": 1.6360000000000001,
      "grad_norm": 0.515750527381897,
      "learning_rate": 9.096e-06,
      "loss": 0.0043,
      "step": 4090
    },
    {
      "epoch": 1.6400000000000001,
      "grad_norm": 0.02951083518564701,
      "learning_rate": 9.069333333333335e-06,
      "loss": 0.0108,
      "step": 4100
    },
    {
      "epoch": 1.6440000000000001,
      "grad_norm": 0.06452522426843643,
      "learning_rate": 9.042666666666667e-06,
      "loss": 0.0127,
      "step": 4110
    },
    {
      "epoch": 1.6480000000000001,
      "grad_norm": 0.06830131262540817,
      "learning_rate": 9.016e-06,
      "loss": 0.0029,
      "step": 4120
    },
    {
      "epoch": 1.6520000000000001,
      "grad_norm": 0.05817916989326477,
      "learning_rate": 8.989333333333334e-06,
      "loss": 0.0049,
      "step": 4130
    },
    {
      "epoch": 1.6560000000000001,
      "grad_norm": 0.33866459131240845,
      "learning_rate": 8.962666666666668e-06,
      "loss": 0.0033,
      "step": 4140
    },
    {
      "epoch": 1.6600000000000001,
      "grad_norm": 0.009843643754720688,
      "learning_rate": 8.936e-06,
      "loss": 0.0053,
      "step": 4150
    },
    {
      "epoch": 1.6640000000000001,
      "grad_norm": 0.5397201180458069,
      "learning_rate": 8.909333333333335e-06,
      "loss": 0.0057,
      "step": 4160
    },
    {
      "epoch": 1.6680000000000001,
      "grad_norm": 0.09942051023244858,
      "learning_rate": 8.882666666666667e-06,
      "loss": 0.0103,
      "step": 4170
    },
    {
      "epoch": 1.6720000000000002,
      "grad_norm": 0.11978405714035034,
      "learning_rate": 8.856000000000001e-06,
      "loss": 0.0043,
      "step": 4180
    },
    {
      "epoch": 1.6760000000000002,
      "grad_norm": 0.11654416471719742,
      "learning_rate": 8.829333333333334e-06,
      "loss": 0.0133,
      "step": 4190
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 2.7184107303619385,
      "learning_rate": 8.802666666666668e-06,
      "loss": 0.0144,
      "step": 4200
    },
    {
      "epoch": 1.6840000000000002,
      "grad_norm": 0.0533183254301548,
      "learning_rate": 8.776e-06,
      "loss": 0.0097,
      "step": 4210
    },
    {
      "epoch": 1.688,
      "grad_norm": 0.9700902700424194,
      "learning_rate": 8.749333333333334e-06,
      "loss": 0.0133,
      "step": 4220
    },
    {
      "epoch": 1.692,
      "grad_norm": 0.0542241595685482,
      "learning_rate": 8.722666666666667e-06,
      "loss": 0.0033,
      "step": 4230
    },
    {
      "epoch": 1.696,
      "grad_norm": 0.037394557148218155,
      "learning_rate": 8.696000000000001e-06,
      "loss": 0.0031,
      "step": 4240
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.15356603264808655,
      "learning_rate": 8.669333333333334e-06,
      "loss": 0.0086,
      "step": 4250
    },
    {
      "epoch": 1.704,
      "grad_norm": 0.21820197999477386,
      "learning_rate": 8.642666666666668e-06,
      "loss": 0.0144,
      "step": 4260
    },
    {
      "epoch": 1.708,
      "grad_norm": 0.017262469977140427,
      "learning_rate": 8.616000000000002e-06,
      "loss": 0.0051,
      "step": 4270
    },
    {
      "epoch": 1.712,
      "grad_norm": 0.04886854067444801,
      "learning_rate": 8.589333333333334e-06,
      "loss": 0.008,
      "step": 4280
    },
    {
      "epoch": 1.716,
      "grad_norm": 0.33239057660102844,
      "learning_rate": 8.562666666666667e-06,
      "loss": 0.0075,
      "step": 4290
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.31250569224357605,
      "learning_rate": 8.536000000000001e-06,
      "loss": 0.0055,
      "step": 4300
    },
    {
      "epoch": 1.724,
      "grad_norm": 0.32860612869262695,
      "learning_rate": 8.509333333333333e-06,
      "loss": 0.0093,
      "step": 4310
    },
    {
      "epoch": 1.728,
      "grad_norm": 0.1801784634590149,
      "learning_rate": 8.482666666666668e-06,
      "loss": 0.0038,
      "step": 4320
    },
    {
      "epoch": 1.732,
      "grad_norm": 0.29676344990730286,
      "learning_rate": 8.456000000000002e-06,
      "loss": 0.0074,
      "step": 4330
    },
    {
      "epoch": 1.736,
      "grad_norm": 0.031166531145572662,
      "learning_rate": 8.429333333333334e-06,
      "loss": 0.0083,
      "step": 4340
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.5975764989852905,
      "learning_rate": 8.402666666666668e-06,
      "loss": 0.0083,
      "step": 4350
    },
    {
      "epoch": 1.744,
      "grad_norm": 0.09026189148426056,
      "learning_rate": 8.376e-06,
      "loss": 0.002,
      "step": 4360
    },
    {
      "epoch": 1.748,
      "grad_norm": 0.020850026980042458,
      "learning_rate": 8.349333333333333e-06,
      "loss": 0.0104,
      "step": 4370
    },
    {
      "epoch": 1.752,
      "grad_norm": 0.3296748995780945,
      "learning_rate": 8.322666666666667e-06,
      "loss": 0.0184,
      "step": 4380
    },
    {
      "epoch": 1.756,
      "grad_norm": 0.2921501100063324,
      "learning_rate": 8.296000000000002e-06,
      "loss": 0.0067,
      "step": 4390
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.022145206108689308,
      "learning_rate": 8.269333333333334e-06,
      "loss": 0.0057,
      "step": 4400
    },
    {
      "epoch": 1.764,
      "grad_norm": 0.1590217500925064,
      "learning_rate": 8.242666666666668e-06,
      "loss": 0.0101,
      "step": 4410
    },
    {
      "epoch": 1.768,
      "grad_norm": 0.21881388127803802,
      "learning_rate": 8.216e-06,
      "loss": 0.0026,
      "step": 4420
    },
    {
      "epoch": 1.772,
      "grad_norm": 0.4069144129753113,
      "learning_rate": 8.189333333333333e-06,
      "loss": 0.012,
      "step": 4430
    },
    {
      "epoch": 1.776,
      "grad_norm": 0.6770957112312317,
      "learning_rate": 8.162666666666667e-06,
      "loss": 0.0045,
      "step": 4440
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.21925115585327148,
      "learning_rate": 8.136000000000001e-06,
      "loss": 0.0079,
      "step": 4450
    },
    {
      "epoch": 1.784,
      "grad_norm": 0.17660357058048248,
      "learning_rate": 8.109333333333334e-06,
      "loss": 0.0062,
      "step": 4460
    },
    {
      "epoch": 1.788,
      "grad_norm": 0.0171713437885046,
      "learning_rate": 8.082666666666668e-06,
      "loss": 0.0065,
      "step": 4470
    },
    {
      "epoch": 1.792,
      "grad_norm": 0.21636028587818146,
      "learning_rate": 8.056e-06,
      "loss": 0.0051,
      "step": 4480
    },
    {
      "epoch": 1.796,
      "grad_norm": 0.014709417708218098,
      "learning_rate": 8.029333333333335e-06,
      "loss": 0.0065,
      "step": 4490
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.021593213081359863,
      "learning_rate": 8.002666666666667e-06,
      "loss": 0.0099,
      "step": 4500
    },
    {
      "epoch": 1.804,
      "grad_norm": 0.155303493142128,
      "learning_rate": 7.976000000000001e-06,
      "loss": 0.0032,
      "step": 4510
    },
    {
      "epoch": 1.808,
      "grad_norm": 0.08275545388460159,
      "learning_rate": 7.949333333333334e-06,
      "loss": 0.0077,
      "step": 4520
    },
    {
      "epoch": 1.812,
      "grad_norm": 0.48293712735176086,
      "learning_rate": 7.922666666666668e-06,
      "loss": 0.009,
      "step": 4530
    },
    {
      "epoch": 1.8159999999999998,
      "grad_norm": 0.09317409247159958,
      "learning_rate": 7.896e-06,
      "loss": 0.0042,
      "step": 4540
    },
    {
      "epoch": 1.8199999999999998,
      "grad_norm": 0.01735200360417366,
      "learning_rate": 7.869333333333334e-06,
      "loss": 0.0038,
      "step": 4550
    },
    {
      "epoch": 1.8239999999999998,
      "grad_norm": 0.0660891979932785,
      "learning_rate": 7.842666666666667e-06,
      "loss": 0.0104,
      "step": 4560
    },
    {
      "epoch": 1.8279999999999998,
      "grad_norm": 0.2996135652065277,
      "learning_rate": 7.816000000000001e-06,
      "loss": 0.0057,
      "step": 4570
    },
    {
      "epoch": 1.8319999999999999,
      "grad_norm": 0.6950057148933411,
      "learning_rate": 7.789333333333334e-06,
      "loss": 0.0029,
      "step": 4580
    },
    {
      "epoch": 1.8359999999999999,
      "grad_norm": 0.5895545482635498,
      "learning_rate": 7.762666666666668e-06,
      "loss": 0.0063,
      "step": 4590
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 0.013157340697944164,
      "learning_rate": 7.736e-06,
      "loss": 0.0095,
      "step": 4600
    },
    {
      "epoch": 1.8439999999999999,
      "grad_norm": 0.2764246165752411,
      "learning_rate": 7.709333333333334e-06,
      "loss": 0.0073,
      "step": 4610
    },
    {
      "epoch": 1.8479999999999999,
      "grad_norm": 0.952181875705719,
      "learning_rate": 7.682666666666667e-06,
      "loss": 0.0088,
      "step": 4620
    },
    {
      "epoch": 1.8519999999999999,
      "grad_norm": 0.052016109228134155,
      "learning_rate": 7.656000000000001e-06,
      "loss": 0.0072,
      "step": 4630
    },
    {
      "epoch": 1.8559999999999999,
      "grad_norm": 0.3900219202041626,
      "learning_rate": 7.629333333333334e-06,
      "loss": 0.0062,
      "step": 4640
    },
    {
      "epoch": 1.8599999999999999,
      "grad_norm": 0.023553306236863136,
      "learning_rate": 7.602666666666667e-06,
      "loss": 0.0052,
      "step": 4650
    },
    {
      "epoch": 1.8639999999999999,
      "grad_norm": 0.013856759294867516,
      "learning_rate": 7.576000000000001e-06,
      "loss": 0.0028,
      "step": 4660
    },
    {
      "epoch": 1.8679999999999999,
      "grad_norm": 0.035608354955911636,
      "learning_rate": 7.549333333333334e-06,
      "loss": 0.0035,
      "step": 4670
    },
    {
      "epoch": 1.8719999999999999,
      "grad_norm": 0.027386711910367012,
      "learning_rate": 7.522666666666667e-06,
      "loss": 0.0111,
      "step": 4680
    },
    {
      "epoch": 1.876,
      "grad_norm": 0.10247645527124405,
      "learning_rate": 7.496000000000001e-06,
      "loss": 0.002,
      "step": 4690
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.3206392824649811,
      "learning_rate": 7.469333333333334e-06,
      "loss": 0.0097,
      "step": 4700
    },
    {
      "epoch": 1.884,
      "grad_norm": 1.4238697290420532,
      "learning_rate": 7.442666666666667e-06,
      "loss": 0.0042,
      "step": 4710
    },
    {
      "epoch": 1.888,
      "grad_norm": 0.061806753277778625,
      "learning_rate": 7.416000000000001e-06,
      "loss": 0.0017,
      "step": 4720
    },
    {
      "epoch": 1.892,
      "grad_norm": 0.1947483867406845,
      "learning_rate": 7.389333333333334e-06,
      "loss": 0.0147,
      "step": 4730
    },
    {
      "epoch": 1.896,
      "grad_norm": 0.7261702418327332,
      "learning_rate": 7.362666666666667e-06,
      "loss": 0.0092,
      "step": 4740
    },
    {
      "epoch": 1.9,
      "grad_norm": 1.567871332168579,
      "learning_rate": 7.3360000000000006e-06,
      "loss": 0.0127,
      "step": 4750
    },
    {
      "epoch": 1.904,
      "grad_norm": 0.09475870430469513,
      "learning_rate": 7.309333333333334e-06,
      "loss": 0.0085,
      "step": 4760
    },
    {
      "epoch": 1.908,
      "grad_norm": 0.10369347035884857,
      "learning_rate": 7.282666666666667e-06,
      "loss": 0.0035,
      "step": 4770
    },
    {
      "epoch": 1.912,
      "grad_norm": 0.10095955431461334,
      "learning_rate": 7.2560000000000005e-06,
      "loss": 0.0091,
      "step": 4780
    },
    {
      "epoch": 1.916,
      "grad_norm": 0.8527160286903381,
      "learning_rate": 7.229333333333334e-06,
      "loss": 0.0051,
      "step": 4790
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.058192186057567596,
      "learning_rate": 7.202666666666668e-06,
      "loss": 0.006,
      "step": 4800
    },
    {
      "epoch": 1.924,
      "grad_norm": 0.06704708933830261,
      "learning_rate": 7.176e-06,
      "loss": 0.0052,
      "step": 4810
    },
    {
      "epoch": 1.928,
      "grad_norm": 0.1826116442680359,
      "learning_rate": 7.149333333333334e-06,
      "loss": 0.0055,
      "step": 4820
    },
    {
      "epoch": 1.932,
      "grad_norm": 0.06371591240167618,
      "learning_rate": 7.122666666666668e-06,
      "loss": 0.0139,
      "step": 4830
    },
    {
      "epoch": 1.936,
      "grad_norm": 0.10931184887886047,
      "learning_rate": 7.096e-06,
      "loss": 0.0019,
      "step": 4840
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.009483727626502514,
      "learning_rate": 7.069333333333334e-06,
      "loss": 0.0064,
      "step": 4850
    },
    {
      "epoch": 1.944,
      "grad_norm": 0.00858821626752615,
      "learning_rate": 7.042666666666668e-06,
      "loss": 0.0037,
      "step": 4860
    },
    {
      "epoch": 1.948,
      "grad_norm": 0.5052180886268616,
      "learning_rate": 7.016e-06,
      "loss": 0.0101,
      "step": 4870
    },
    {
      "epoch": 1.952,
      "grad_norm": 0.746134877204895,
      "learning_rate": 6.9893333333333336e-06,
      "loss": 0.0073,
      "step": 4880
    },
    {
      "epoch": 1.956,
      "grad_norm": 0.015750672668218613,
      "learning_rate": 6.962666666666668e-06,
      "loss": 0.0042,
      "step": 4890
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.04738178104162216,
      "learning_rate": 6.936e-06,
      "loss": 0.0033,
      "step": 4900
    },
    {
      "epoch": 1.964,
      "grad_norm": 0.15814408659934998,
      "learning_rate": 6.9093333333333335e-06,
      "loss": 0.0082,
      "step": 4910
    },
    {
      "epoch": 1.968,
      "grad_norm": 0.7200542092323303,
      "learning_rate": 6.882666666666668e-06,
      "loss": 0.0095,
      "step": 4920
    },
    {
      "epoch": 1.972,
      "grad_norm": 0.40974757075309753,
      "learning_rate": 6.856e-06,
      "loss": 0.0047,
      "step": 4930
    },
    {
      "epoch": 1.976,
      "grad_norm": 0.9785233736038208,
      "learning_rate": 6.829333333333333e-06,
      "loss": 0.0022,
      "step": 4940
    },
    {
      "epoch": 1.98,
      "grad_norm": 0.10968407988548279,
      "learning_rate": 6.8026666666666675e-06,
      "loss": 0.0123,
      "step": 4950
    },
    {
      "epoch": 1.984,
      "grad_norm": 0.011374358087778091,
      "learning_rate": 6.776e-06,
      "loss": 0.0029,
      "step": 4960
    },
    {
      "epoch": 1.988,
      "grad_norm": 0.020572766661643982,
      "learning_rate": 6.749333333333334e-06,
      "loss": 0.007,
      "step": 4970
    },
    {
      "epoch": 1.992,
      "grad_norm": 0.0063086445443332195,
      "learning_rate": 6.7226666666666675e-06,
      "loss": 0.004,
      "step": 4980
    },
    {
      "epoch": 1.996,
      "grad_norm": 0.8627201318740845,
      "learning_rate": 6.696e-06,
      "loss": 0.01,
      "step": 4990
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.42741841077804565,
      "learning_rate": 6.669333333333334e-06,
      "loss": 0.0016,
      "step": 5000
    },
    {
      "epoch": 2.004,
      "grad_norm": 0.03651900216937065,
      "learning_rate": 6.642666666666667e-06,
      "loss": 0.0023,
      "step": 5010
    },
    {
      "epoch": 2.008,
      "grad_norm": 0.19151687622070312,
      "learning_rate": 6.616e-06,
      "loss": 0.0031,
      "step": 5020
    },
    {
      "epoch": 2.012,
      "grad_norm": 0.005056182853877544,
      "learning_rate": 6.589333333333334e-06,
      "loss": 0.002,
      "step": 5030
    },
    {
      "epoch": 2.016,
      "grad_norm": 0.008571538142859936,
      "learning_rate": 6.562666666666667e-06,
      "loss": 0.0063,
      "step": 5040
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.1163473054766655,
      "learning_rate": 6.536e-06,
      "loss": 0.0066,
      "step": 5050
    },
    {
      "epoch": 2.024,
      "grad_norm": 0.2075250893831253,
      "learning_rate": 6.509333333333334e-06,
      "loss": 0.0037,
      "step": 5060
    },
    {
      "epoch": 2.028,
      "grad_norm": 0.0938650444149971,
      "learning_rate": 6.482666666666667e-06,
      "loss": 0.0035,
      "step": 5070
    },
    {
      "epoch": 2.032,
      "grad_norm": 0.03992224112153053,
      "learning_rate": 6.456e-06,
      "loss": 0.0047,
      "step": 5080
    },
    {
      "epoch": 2.036,
      "grad_norm": 0.0442955456674099,
      "learning_rate": 6.429333333333334e-06,
      "loss": 0.0037,
      "step": 5090
    },
    {
      "epoch": 2.04,
      "grad_norm": 0.16081051528453827,
      "learning_rate": 6.402666666666667e-06,
      "loss": 0.0082,
      "step": 5100
    },
    {
      "epoch": 2.044,
      "grad_norm": 0.10423558205366135,
      "learning_rate": 6.376e-06,
      "loss": 0.0022,
      "step": 5110
    },
    {
      "epoch": 2.048,
      "grad_norm": 0.030201518908143044,
      "learning_rate": 6.349333333333334e-06,
      "loss": 0.0078,
      "step": 5120
    },
    {
      "epoch": 2.052,
      "grad_norm": 0.6084281206130981,
      "learning_rate": 6.322666666666667e-06,
      "loss": 0.004,
      "step": 5130
    },
    {
      "epoch": 2.056,
      "grad_norm": 0.0117934076115489,
      "learning_rate": 6.296000000000001e-06,
      "loss": 0.0025,
      "step": 5140
    },
    {
      "epoch": 2.06,
      "grad_norm": 0.028844675049185753,
      "learning_rate": 6.269333333333334e-06,
      "loss": 0.0047,
      "step": 5150
    },
    {
      "epoch": 2.064,
      "grad_norm": 0.373830646276474,
      "learning_rate": 6.242666666666667e-06,
      "loss": 0.0055,
      "step": 5160
    },
    {
      "epoch": 2.068,
      "grad_norm": 0.007582406513392925,
      "learning_rate": 6.216000000000001e-06,
      "loss": 0.0031,
      "step": 5170
    },
    {
      "epoch": 2.072,
      "grad_norm": 0.06596601009368896,
      "learning_rate": 6.189333333333334e-06,
      "loss": 0.0173,
      "step": 5180
    },
    {
      "epoch": 2.076,
      "grad_norm": 0.21714259684085846,
      "learning_rate": 6.162666666666667e-06,
      "loss": 0.0044,
      "step": 5190
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.1152748093008995,
      "learning_rate": 6.136000000000001e-06,
      "loss": 0.004,
      "step": 5200
    },
    {
      "epoch": 2.084,
      "grad_norm": 0.08087003231048584,
      "learning_rate": 6.1093333333333335e-06,
      "loss": 0.0028,
      "step": 5210
    },
    {
      "epoch": 2.088,
      "grad_norm": 2.4975783824920654,
      "learning_rate": 6.082666666666667e-06,
      "loss": 0.0071,
      "step": 5220
    },
    {
      "epoch": 2.092,
      "grad_norm": 0.12394600361585617,
      "learning_rate": 6.056000000000001e-06,
      "loss": 0.0076,
      "step": 5230
    },
    {
      "epoch": 2.096,
      "grad_norm": 0.06965024769306183,
      "learning_rate": 6.0293333333333334e-06,
      "loss": 0.0044,
      "step": 5240
    },
    {
      "epoch": 2.1,
      "grad_norm": 0.03046511486172676,
      "learning_rate": 6.002666666666667e-06,
      "loss": 0.0033,
      "step": 5250
    },
    {
      "epoch": 2.104,
      "grad_norm": 0.3748788833618164,
      "learning_rate": 5.976000000000001e-06,
      "loss": 0.0017,
      "step": 5260
    },
    {
      "epoch": 2.108,
      "grad_norm": 0.5066462755203247,
      "learning_rate": 5.949333333333333e-06,
      "loss": 0.0109,
      "step": 5270
    },
    {
      "epoch": 2.112,
      "grad_norm": 0.06996286660432816,
      "learning_rate": 5.9226666666666675e-06,
      "loss": 0.0017,
      "step": 5280
    },
    {
      "epoch": 2.116,
      "grad_norm": 0.033132404088974,
      "learning_rate": 5.896000000000001e-06,
      "loss": 0.0025,
      "step": 5290
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.021832836791872978,
      "learning_rate": 5.869333333333333e-06,
      "loss": 0.0029,
      "step": 5300
    },
    {
      "epoch": 2.124,
      "grad_norm": 0.14882436394691467,
      "learning_rate": 5.842666666666667e-06,
      "loss": 0.0029,
      "step": 5310
    },
    {
      "epoch": 2.128,
      "grad_norm": 0.12119399011135101,
      "learning_rate": 5.816000000000001e-06,
      "loss": 0.0033,
      "step": 5320
    },
    {
      "epoch": 2.132,
      "grad_norm": 0.20211458206176758,
      "learning_rate": 5.789333333333333e-06,
      "loss": 0.0035,
      "step": 5330
    },
    {
      "epoch": 2.136,
      "grad_norm": 0.8242979645729065,
      "learning_rate": 5.762666666666667e-06,
      "loss": 0.0035,
      "step": 5340
    },
    {
      "epoch": 2.14,
      "grad_norm": 0.013538719154894352,
      "learning_rate": 5.736000000000001e-06,
      "loss": 0.0023,
      "step": 5350
    },
    {
      "epoch": 2.144,
      "grad_norm": 1.1666840314865112,
      "learning_rate": 5.709333333333333e-06,
      "loss": 0.0125,
      "step": 5360
    },
    {
      "epoch": 2.148,
      "grad_norm": 0.13367418944835663,
      "learning_rate": 5.682666666666667e-06,
      "loss": 0.0058,
      "step": 5370
    },
    {
      "epoch": 2.152,
      "grad_norm": 0.05326136574149132,
      "learning_rate": 5.6560000000000006e-06,
      "loss": 0.0016,
      "step": 5380
    },
    {
      "epoch": 2.156,
      "grad_norm": 0.6045821309089661,
      "learning_rate": 5.629333333333333e-06,
      "loss": 0.0033,
      "step": 5390
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.008955676108598709,
      "learning_rate": 5.602666666666667e-06,
      "loss": 0.0041,
      "step": 5400
    },
    {
      "epoch": 2.164,
      "grad_norm": 0.07197318971157074,
      "learning_rate": 5.5760000000000005e-06,
      "loss": 0.0094,
      "step": 5410
    },
    {
      "epoch": 2.168,
      "grad_norm": 0.017503023147583008,
      "learning_rate": 5.549333333333333e-06,
      "loss": 0.0041,
      "step": 5420
    },
    {
      "epoch": 2.172,
      "grad_norm": 0.018601227551698685,
      "learning_rate": 5.522666666666667e-06,
      "loss": 0.0039,
      "step": 5430
    },
    {
      "epoch": 2.176,
      "grad_norm": 0.5398707389831543,
      "learning_rate": 5.496e-06,
      "loss": 0.0115,
      "step": 5440
    },
    {
      "epoch": 2.18,
      "grad_norm": 0.4221554696559906,
      "learning_rate": 5.4693333333333346e-06,
      "loss": 0.0018,
      "step": 5450
    },
    {
      "epoch": 2.184,
      "grad_norm": 0.020490001887083054,
      "learning_rate": 5.442666666666667e-06,
      "loss": 0.0088,
      "step": 5460
    },
    {
      "epoch": 2.188,
      "grad_norm": 0.1232120469212532,
      "learning_rate": 5.416e-06,
      "loss": 0.001,
      "step": 5470
    },
    {
      "epoch": 2.192,
      "grad_norm": 0.13987913727760315,
      "learning_rate": 5.3893333333333345e-06,
      "loss": 0.0149,
      "step": 5480
    },
    {
      "epoch": 2.196,
      "grad_norm": 0.1729057878255844,
      "learning_rate": 5.362666666666667e-06,
      "loss": 0.0017,
      "step": 5490
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.07804952561855316,
      "learning_rate": 5.336e-06,
      "loss": 0.002,
      "step": 5500
    },
    {
      "epoch": 2.204,
      "grad_norm": 0.16080917418003082,
      "learning_rate": 5.309333333333334e-06,
      "loss": 0.0042,
      "step": 5510
    },
    {
      "epoch": 2.208,
      "grad_norm": 0.04084566608071327,
      "learning_rate": 5.282666666666667e-06,
      "loss": 0.0061,
      "step": 5520
    },
    {
      "epoch": 2.212,
      "grad_norm": 1.0300970077514648,
      "learning_rate": 5.256e-06,
      "loss": 0.0017,
      "step": 5530
    },
    {
      "epoch": 2.216,
      "grad_norm": 0.17586664855480194,
      "learning_rate": 5.229333333333334e-06,
      "loss": 0.0044,
      "step": 5540
    },
    {
      "epoch": 2.22,
      "grad_norm": 0.4648432731628418,
      "learning_rate": 5.202666666666667e-06,
      "loss": 0.0036,
      "step": 5550
    },
    {
      "epoch": 2.224,
      "grad_norm": 0.016487520188093185,
      "learning_rate": 5.176e-06,
      "loss": 0.0071,
      "step": 5560
    },
    {
      "epoch": 2.228,
      "grad_norm": 0.028221746906638145,
      "learning_rate": 5.149333333333334e-06,
      "loss": 0.0008,
      "step": 5570
    },
    {
      "epoch": 2.232,
      "grad_norm": 0.9440500736236572,
      "learning_rate": 5.122666666666667e-06,
      "loss": 0.002,
      "step": 5580
    },
    {
      "epoch": 2.2359999999999998,
      "grad_norm": 0.09186737984418869,
      "learning_rate": 5.096000000000001e-06,
      "loss": 0.005,
      "step": 5590
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.1607033759355545,
      "learning_rate": 5.069333333333334e-06,
      "loss": 0.0047,
      "step": 5600
    },
    {
      "epoch": 2.2439999999999998,
      "grad_norm": 0.0046082125045359135,
      "learning_rate": 5.042666666666667e-06,
      "loss": 0.0021,
      "step": 5610
    },
    {
      "epoch": 2.248,
      "grad_norm": 0.06116350740194321,
      "learning_rate": 5.016000000000001e-06,
      "loss": 0.0052,
      "step": 5620
    },
    {
      "epoch": 2.252,
      "grad_norm": 0.025363698601722717,
      "learning_rate": 4.989333333333334e-06,
      "loss": 0.0009,
      "step": 5630
    },
    {
      "epoch": 2.2560000000000002,
      "grad_norm": 0.02540549822151661,
      "learning_rate": 4.962666666666667e-06,
      "loss": 0.0029,
      "step": 5640
    },
    {
      "epoch": 2.26,
      "grad_norm": 0.47851309180259705,
      "learning_rate": 4.936e-06,
      "loss": 0.0031,
      "step": 5650
    },
    {
      "epoch": 2.2640000000000002,
      "grad_norm": 0.03036840260028839,
      "learning_rate": 4.909333333333334e-06,
      "loss": 0.0053,
      "step": 5660
    },
    {
      "epoch": 2.268,
      "grad_norm": 0.02335761860013008,
      "learning_rate": 4.882666666666667e-06,
      "loss": 0.0016,
      "step": 5670
    },
    {
      "epoch": 2.2720000000000002,
      "grad_norm": 0.011766782961785793,
      "learning_rate": 4.856e-06,
      "loss": 0.0034,
      "step": 5680
    },
    {
      "epoch": 2.276,
      "grad_norm": 0.365906298160553,
      "learning_rate": 4.829333333333334e-06,
      "loss": 0.0048,
      "step": 5690
    },
    {
      "epoch": 2.2800000000000002,
      "grad_norm": 0.05951082333922386,
      "learning_rate": 4.802666666666667e-06,
      "loss": 0.0041,
      "step": 5700
    },
    {
      "epoch": 2.284,
      "grad_norm": 0.017320754006505013,
      "learning_rate": 4.7760000000000005e-06,
      "loss": 0.0046,
      "step": 5710
    },
    {
      "epoch": 2.288,
      "grad_norm": 0.13824555277824402,
      "learning_rate": 4.749333333333334e-06,
      "loss": 0.0027,
      "step": 5720
    },
    {
      "epoch": 2.292,
      "grad_norm": 0.364096075296402,
      "learning_rate": 4.722666666666667e-06,
      "loss": 0.0087,
      "step": 5730
    },
    {
      "epoch": 2.296,
      "grad_norm": 0.023708513006567955,
      "learning_rate": 4.6960000000000004e-06,
      "loss": 0.0036,
      "step": 5740
    },
    {
      "epoch": 2.3,
      "grad_norm": 0.029233483597636223,
      "learning_rate": 4.669333333333334e-06,
      "loss": 0.0059,
      "step": 5750
    },
    {
      "epoch": 2.304,
      "grad_norm": 0.01760932058095932,
      "learning_rate": 4.642666666666667e-06,
      "loss": 0.001,
      "step": 5760
    },
    {
      "epoch": 2.308,
      "grad_norm": 0.7956658601760864,
      "learning_rate": 4.616e-06,
      "loss": 0.0126,
      "step": 5770
    },
    {
      "epoch": 2.312,
      "grad_norm": 0.020741241052746773,
      "learning_rate": 4.589333333333334e-06,
      "loss": 0.0012,
      "step": 5780
    },
    {
      "epoch": 2.316,
      "grad_norm": 0.077226921916008,
      "learning_rate": 4.562666666666667e-06,
      "loss": 0.0051,
      "step": 5790
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.016674907878041267,
      "learning_rate": 4.536e-06,
      "loss": 0.0066,
      "step": 5800
    },
    {
      "epoch": 2.324,
      "grad_norm": 0.14121493697166443,
      "learning_rate": 4.509333333333334e-06,
      "loss": 0.0033,
      "step": 5810
    },
    {
      "epoch": 2.328,
      "grad_norm": 0.0182135459035635,
      "learning_rate": 4.482666666666667e-06,
      "loss": 0.0054,
      "step": 5820
    },
    {
      "epoch": 2.332,
      "grad_norm": 0.49520036578178406,
      "learning_rate": 4.456e-06,
      "loss": 0.0077,
      "step": 5830
    },
    {
      "epoch": 2.336,
      "grad_norm": 0.03813542425632477,
      "learning_rate": 4.4293333333333335e-06,
      "loss": 0.0016,
      "step": 5840
    },
    {
      "epoch": 2.34,
      "grad_norm": 0.8331297039985657,
      "learning_rate": 4.402666666666667e-06,
      "loss": 0.0063,
      "step": 5850
    },
    {
      "epoch": 2.344,
      "grad_norm": 0.12821877002716064,
      "learning_rate": 4.376e-06,
      "loss": 0.0027,
      "step": 5860
    },
    {
      "epoch": 2.348,
      "grad_norm": 0.1530548483133316,
      "learning_rate": 4.349333333333333e-06,
      "loss": 0.0013,
      "step": 5870
    },
    {
      "epoch": 2.352,
      "grad_norm": 0.006666232366114855,
      "learning_rate": 4.3226666666666676e-06,
      "loss": 0.0012,
      "step": 5880
    },
    {
      "epoch": 2.356,
      "grad_norm": 1.0711976289749146,
      "learning_rate": 4.296e-06,
      "loss": 0.0021,
      "step": 5890
    },
    {
      "epoch": 2.36,
      "grad_norm": 0.026236457750201225,
      "learning_rate": 4.269333333333333e-06,
      "loss": 0.001,
      "step": 5900
    },
    {
      "epoch": 2.364,
      "grad_norm": 0.0045605492778122425,
      "learning_rate": 4.2426666666666675e-06,
      "loss": 0.0023,
      "step": 5910
    },
    {
      "epoch": 2.368,
      "grad_norm": 0.0733136236667633,
      "learning_rate": 4.216e-06,
      "loss": 0.0009,
      "step": 5920
    },
    {
      "epoch": 2.372,
      "grad_norm": 0.004109554924070835,
      "learning_rate": 4.189333333333333e-06,
      "loss": 0.0078,
      "step": 5930
    },
    {
      "epoch": 2.376,
      "grad_norm": 0.02715451642870903,
      "learning_rate": 4.162666666666667e-06,
      "loss": 0.0033,
      "step": 5940
    },
    {
      "epoch": 2.38,
      "grad_norm": 0.06403839588165283,
      "learning_rate": 4.136000000000001e-06,
      "loss": 0.0008,
      "step": 5950
    },
    {
      "epoch": 2.384,
      "grad_norm": 0.6217687726020813,
      "learning_rate": 4.109333333333333e-06,
      "loss": 0.0029,
      "step": 5960
    },
    {
      "epoch": 2.388,
      "grad_norm": 0.8216224908828735,
      "learning_rate": 4.082666666666667e-06,
      "loss": 0.0036,
      "step": 5970
    },
    {
      "epoch": 2.392,
      "grad_norm": 0.4060487449169159,
      "learning_rate": 4.056000000000001e-06,
      "loss": 0.001,
      "step": 5980
    },
    {
      "epoch": 2.396,
      "grad_norm": 0.005055399611592293,
      "learning_rate": 4.029333333333333e-06,
      "loss": 0.0011,
      "step": 5990
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.0022644521668553352,
      "learning_rate": 4.002666666666667e-06,
      "loss": 0.001,
      "step": 6000
    },
    {
      "epoch": 2.404,
      "grad_norm": 0.033568382263183594,
      "learning_rate": 3.9760000000000006e-06,
      "loss": 0.0079,
      "step": 6010
    },
    {
      "epoch": 2.408,
      "grad_norm": 0.21404094994068146,
      "learning_rate": 3.949333333333334e-06,
      "loss": 0.001,
      "step": 6020
    },
    {
      "epoch": 2.412,
      "grad_norm": 0.009559476748108864,
      "learning_rate": 3.922666666666667e-06,
      "loss": 0.002,
      "step": 6030
    },
    {
      "epoch": 2.416,
      "grad_norm": 0.4422765374183655,
      "learning_rate": 3.8960000000000005e-06,
      "loss": 0.0055,
      "step": 6040
    },
    {
      "epoch": 2.42,
      "grad_norm": 3.1309380531311035,
      "learning_rate": 3.869333333333334e-06,
      "loss": 0.0069,
      "step": 6050
    },
    {
      "epoch": 2.424,
      "grad_norm": 0.017924852669239044,
      "learning_rate": 3.842666666666667e-06,
      "loss": 0.0014,
      "step": 6060
    },
    {
      "epoch": 2.428,
      "grad_norm": 0.012339840643107891,
      "learning_rate": 3.816e-06,
      "loss": 0.0065,
      "step": 6070
    },
    {
      "epoch": 2.432,
      "grad_norm": 0.01700114831328392,
      "learning_rate": 3.7893333333333337e-06,
      "loss": 0.0054,
      "step": 6080
    },
    {
      "epoch": 2.436,
      "grad_norm": 0.5305489301681519,
      "learning_rate": 3.7626666666666674e-06,
      "loss": 0.0017,
      "step": 6090
    },
    {
      "epoch": 2.44,
      "grad_norm": 0.031726475805044174,
      "learning_rate": 3.7360000000000003e-06,
      "loss": 0.0041,
      "step": 6100
    },
    {
      "epoch": 2.444,
      "grad_norm": 0.09764041006565094,
      "learning_rate": 3.7093333333333336e-06,
      "loss": 0.0022,
      "step": 6110
    },
    {
      "epoch": 2.448,
      "grad_norm": 0.01572890393435955,
      "learning_rate": 3.6826666666666673e-06,
      "loss": 0.0066,
      "step": 6120
    },
    {
      "epoch": 2.452,
      "grad_norm": 0.003641363000497222,
      "learning_rate": 3.6560000000000002e-06,
      "loss": 0.0019,
      "step": 6130
    },
    {
      "epoch": 2.456,
      "grad_norm": 0.02302863448858261,
      "learning_rate": 3.6293333333333335e-06,
      "loss": 0.0005,
      "step": 6140
    },
    {
      "epoch": 2.46,
      "grad_norm": 0.013508124276995659,
      "learning_rate": 3.6026666666666673e-06,
      "loss": 0.0085,
      "step": 6150
    },
    {
      "epoch": 2.464,
      "grad_norm": 0.16255904734134674,
      "learning_rate": 3.576e-06,
      "loss": 0.0019,
      "step": 6160
    },
    {
      "epoch": 2.468,
      "grad_norm": 0.041559044271707535,
      "learning_rate": 3.5493333333333335e-06,
      "loss": 0.0053,
      "step": 6170
    },
    {
      "epoch": 2.472,
      "grad_norm": 0.4894736409187317,
      "learning_rate": 3.522666666666667e-06,
      "loss": 0.007,
      "step": 6180
    },
    {
      "epoch": 2.476,
      "grad_norm": 0.010386910289525986,
      "learning_rate": 3.4960000000000005e-06,
      "loss": 0.0087,
      "step": 6190
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.03955133259296417,
      "learning_rate": 3.4693333333333334e-06,
      "loss": 0.0014,
      "step": 6200
    },
    {
      "epoch": 2.484,
      "grad_norm": 0.1467614620923996,
      "learning_rate": 3.442666666666667e-06,
      "loss": 0.0045,
      "step": 6210
    },
    {
      "epoch": 2.488,
      "grad_norm": 0.01544566173106432,
      "learning_rate": 3.4160000000000004e-06,
      "loss": 0.004,
      "step": 6220
    },
    {
      "epoch": 2.492,
      "grad_norm": 0.25934717059135437,
      "learning_rate": 3.3893333333333333e-06,
      "loss": 0.0047,
      "step": 6230
    },
    {
      "epoch": 2.496,
      "grad_norm": 0.010037359781563282,
      "learning_rate": 3.362666666666667e-06,
      "loss": 0.0038,
      "step": 6240
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.00976115558296442,
      "learning_rate": 3.3360000000000003e-06,
      "loss": 0.0024,
      "step": 6250
    },
    {
      "epoch": 2.504,
      "grad_norm": 0.23471122980117798,
      "learning_rate": 3.3093333333333336e-06,
      "loss": 0.004,
      "step": 6260
    },
    {
      "epoch": 2.508,
      "grad_norm": 0.06546614319086075,
      "learning_rate": 3.282666666666667e-06,
      "loss": 0.0051,
      "step": 6270
    },
    {
      "epoch": 2.512,
      "grad_norm": 0.03608356788754463,
      "learning_rate": 3.2560000000000003e-06,
      "loss": 0.0007,
      "step": 6280
    },
    {
      "epoch": 2.516,
      "grad_norm": 0.09262287616729736,
      "learning_rate": 3.2293333333333336e-06,
      "loss": 0.0106,
      "step": 6290
    },
    {
      "epoch": 2.52,
      "grad_norm": 0.024731948971748352,
      "learning_rate": 3.202666666666667e-06,
      "loss": 0.0079,
      "step": 6300
    },
    {
      "epoch": 2.524,
      "grad_norm": 0.019236529245972633,
      "learning_rate": 3.176e-06,
      "loss": 0.0048,
      "step": 6310
    },
    {
      "epoch": 2.528,
      "grad_norm": 0.3200666904449463,
      "learning_rate": 3.1493333333333335e-06,
      "loss": 0.0022,
      "step": 6320
    },
    {
      "epoch": 2.532,
      "grad_norm": 0.06793657690286636,
      "learning_rate": 3.122666666666667e-06,
      "loss": 0.0012,
      "step": 6330
    },
    {
      "epoch": 2.536,
      "grad_norm": 0.050981324166059494,
      "learning_rate": 3.096e-06,
      "loss": 0.0087,
      "step": 6340
    },
    {
      "epoch": 2.54,
      "grad_norm": 0.6432188749313354,
      "learning_rate": 3.069333333333334e-06,
      "loss": 0.0033,
      "step": 6350
    },
    {
      "epoch": 2.544,
      "grad_norm": 1.6674615144729614,
      "learning_rate": 3.042666666666667e-06,
      "loss": 0.0149,
      "step": 6360
    },
    {
      "epoch": 2.548,
      "grad_norm": 0.006161255296319723,
      "learning_rate": 3.016e-06,
      "loss": 0.0009,
      "step": 6370
    },
    {
      "epoch": 2.552,
      "grad_norm": 0.19536501169204712,
      "learning_rate": 2.9893333333333337e-06,
      "loss": 0.0015,
      "step": 6380
    },
    {
      "epoch": 2.556,
      "grad_norm": 0.07090890407562256,
      "learning_rate": 2.962666666666667e-06,
      "loss": 0.0028,
      "step": 6390
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.46269676089286804,
      "learning_rate": 2.9360000000000003e-06,
      "loss": 0.0098,
      "step": 6400
    },
    {
      "epoch": 2.564,
      "grad_norm": 0.05314888432621956,
      "learning_rate": 2.9093333333333337e-06,
      "loss": 0.0055,
      "step": 6410
    },
    {
      "epoch": 2.568,
      "grad_norm": 0.035886600613594055,
      "learning_rate": 2.882666666666667e-06,
      "loss": 0.0023,
      "step": 6420
    },
    {
      "epoch": 2.572,
      "grad_norm": 0.06068456918001175,
      "learning_rate": 2.8560000000000003e-06,
      "loss": 0.0039,
      "step": 6430
    },
    {
      "epoch": 2.576,
      "grad_norm": 0.5534144043922424,
      "learning_rate": 2.8293333333333336e-06,
      "loss": 0.0018,
      "step": 6440
    },
    {
      "epoch": 2.58,
      "grad_norm": 0.02773405984044075,
      "learning_rate": 2.802666666666667e-06,
      "loss": 0.0072,
      "step": 6450
    },
    {
      "epoch": 2.584,
      "grad_norm": 0.010442095808684826,
      "learning_rate": 2.776e-06,
      "loss": 0.0032,
      "step": 6460
    },
    {
      "epoch": 2.588,
      "grad_norm": 0.005449822638183832,
      "learning_rate": 2.7493333333333335e-06,
      "loss": 0.0036,
      "step": 6470
    },
    {
      "epoch": 2.592,
      "grad_norm": 0.5547294616699219,
      "learning_rate": 2.722666666666667e-06,
      "loss": 0.0042,
      "step": 6480
    },
    {
      "epoch": 2.596,
      "grad_norm": 0.050688598304986954,
      "learning_rate": 2.696e-06,
      "loss": 0.0046,
      "step": 6490
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.12779369950294495,
      "learning_rate": 2.669333333333334e-06,
      "loss": 0.0053,
      "step": 6500
    },
    {
      "epoch": 2.604,
      "grad_norm": 0.004087210167199373,
      "learning_rate": 2.6426666666666667e-06,
      "loss": 0.0019,
      "step": 6510
    },
    {
      "epoch": 2.608,
      "grad_norm": 1.0497831106185913,
      "learning_rate": 2.616e-06,
      "loss": 0.0048,
      "step": 6520
    },
    {
      "epoch": 2.612,
      "grad_norm": 0.025215020403265953,
      "learning_rate": 2.5893333333333338e-06,
      "loss": 0.001,
      "step": 6530
    },
    {
      "epoch": 2.616,
      "grad_norm": 0.014226900413632393,
      "learning_rate": 2.5626666666666666e-06,
      "loss": 0.0011,
      "step": 6540
    },
    {
      "epoch": 2.62,
      "grad_norm": 0.06457501649856567,
      "learning_rate": 2.536e-06,
      "loss": 0.0044,
      "step": 6550
    },
    {
      "epoch": 2.624,
      "grad_norm": 0.01888100430369377,
      "learning_rate": 2.5093333333333337e-06,
      "loss": 0.0019,
      "step": 6560
    },
    {
      "epoch": 2.628,
      "grad_norm": 0.018688052892684937,
      "learning_rate": 2.482666666666667e-06,
      "loss": 0.0029,
      "step": 6570
    },
    {
      "epoch": 2.632,
      "grad_norm": 0.009642430581152439,
      "learning_rate": 2.4560000000000003e-06,
      "loss": 0.0026,
      "step": 6580
    },
    {
      "epoch": 2.636,
      "grad_norm": 0.25877001881599426,
      "learning_rate": 2.4293333333333336e-06,
      "loss": 0.0028,
      "step": 6590
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.35978496074676514,
      "learning_rate": 2.402666666666667e-06,
      "loss": 0.0024,
      "step": 6600
    },
    {
      "epoch": 2.644,
      "grad_norm": 0.0733645111322403,
      "learning_rate": 2.376e-06,
      "loss": 0.0038,
      "step": 6610
    },
    {
      "epoch": 2.648,
      "grad_norm": 0.013952664099633694,
      "learning_rate": 2.3493333333333335e-06,
      "loss": 0.0012,
      "step": 6620
    },
    {
      "epoch": 2.652,
      "grad_norm": 0.11361482739448547,
      "learning_rate": 2.322666666666667e-06,
      "loss": 0.005,
      "step": 6630
    },
    {
      "epoch": 2.656,
      "grad_norm": 0.19775409996509552,
      "learning_rate": 2.296e-06,
      "loss": 0.0034,
      "step": 6640
    },
    {
      "epoch": 2.66,
      "grad_norm": 0.00568274175748229,
      "learning_rate": 2.2693333333333334e-06,
      "loss": 0.0026,
      "step": 6650
    },
    {
      "epoch": 2.664,
      "grad_norm": 0.13572904467582703,
      "learning_rate": 2.2426666666666667e-06,
      "loss": 0.0124,
      "step": 6660
    },
    {
      "epoch": 2.668,
      "grad_norm": 0.09071886539459229,
      "learning_rate": 2.216e-06,
      "loss": 0.0011,
      "step": 6670
    },
    {
      "epoch": 2.672,
      "grad_norm": 0.04440898820757866,
      "learning_rate": 2.1893333333333338e-06,
      "loss": 0.0038,
      "step": 6680
    },
    {
      "epoch": 2.676,
      "grad_norm": 0.026079431176185608,
      "learning_rate": 2.1626666666666667e-06,
      "loss": 0.0034,
      "step": 6690
    },
    {
      "epoch": 2.68,
      "grad_norm": 0.6010346412658691,
      "learning_rate": 2.1360000000000004e-06,
      "loss": 0.0097,
      "step": 6700
    },
    {
      "epoch": 2.684,
      "grad_norm": 0.02956736460328102,
      "learning_rate": 2.1093333333333337e-06,
      "loss": 0.0027,
      "step": 6710
    },
    {
      "epoch": 2.6879999999999997,
      "grad_norm": 0.4812270998954773,
      "learning_rate": 2.0826666666666666e-06,
      "loss": 0.0049,
      "step": 6720
    },
    {
      "epoch": 2.692,
      "grad_norm": 0.1302318572998047,
      "learning_rate": 2.0560000000000003e-06,
      "loss": 0.0014,
      "step": 6730
    },
    {
      "epoch": 2.6959999999999997,
      "grad_norm": 0.18767188489437103,
      "learning_rate": 2.0293333333333336e-06,
      "loss": 0.0032,
      "step": 6740
    },
    {
      "epoch": 2.7,
      "grad_norm": 0.15765634179115295,
      "learning_rate": 2.002666666666667e-06,
      "loss": 0.0025,
      "step": 6750
    },
    {
      "epoch": 2.7039999999999997,
      "grad_norm": 1.3280599117279053,
      "learning_rate": 1.9760000000000002e-06,
      "loss": 0.0061,
      "step": 6760
    },
    {
      "epoch": 2.708,
      "grad_norm": 0.04272587597370148,
      "learning_rate": 1.9493333333333335e-06,
      "loss": 0.0016,
      "step": 6770
    },
    {
      "epoch": 2.7119999999999997,
      "grad_norm": 0.0380617119371891,
      "learning_rate": 1.922666666666667e-06,
      "loss": 0.0036,
      "step": 6780
    },
    {
      "epoch": 2.716,
      "grad_norm": 0.009174272418022156,
      "learning_rate": 1.8960000000000001e-06,
      "loss": 0.0025,
      "step": 6790
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 0.8805373311042786,
      "learning_rate": 1.8693333333333337e-06,
      "loss": 0.0049,
      "step": 6800
    },
    {
      "epoch": 2.724,
      "grad_norm": 1.0522375106811523,
      "learning_rate": 1.8426666666666668e-06,
      "loss": 0.0027,
      "step": 6810
    },
    {
      "epoch": 2.7279999999999998,
      "grad_norm": 0.017797568812966347,
      "learning_rate": 1.8160000000000003e-06,
      "loss": 0.0009,
      "step": 6820
    },
    {
      "epoch": 2.732,
      "grad_norm": 0.22978395223617554,
      "learning_rate": 1.7893333333333336e-06,
      "loss": 0.001,
      "step": 6830
    },
    {
      "epoch": 2.7359999999999998,
      "grad_norm": 0.23171260952949524,
      "learning_rate": 1.7626666666666667e-06,
      "loss": 0.0031,
      "step": 6840
    },
    {
      "epoch": 2.74,
      "grad_norm": 0.7874360084533691,
      "learning_rate": 1.7360000000000002e-06,
      "loss": 0.0034,
      "step": 6850
    },
    {
      "epoch": 2.7439999999999998,
      "grad_norm": 0.5640131235122681,
      "learning_rate": 1.7093333333333335e-06,
      "loss": 0.0038,
      "step": 6860
    },
    {
      "epoch": 2.748,
      "grad_norm": 1.4999628067016602,
      "learning_rate": 1.6826666666666668e-06,
      "loss": 0.0045,
      "step": 6870
    },
    {
      "epoch": 2.752,
      "grad_norm": 0.06662976741790771,
      "learning_rate": 1.6560000000000001e-06,
      "loss": 0.002,
      "step": 6880
    },
    {
      "epoch": 2.7560000000000002,
      "grad_norm": 0.2797122895717621,
      "learning_rate": 1.6293333333333336e-06,
      "loss": 0.0017,
      "step": 6890
    },
    {
      "epoch": 2.76,
      "grad_norm": 0.018754806369543076,
      "learning_rate": 1.6026666666666667e-06,
      "loss": 0.003,
      "step": 6900
    },
    {
      "epoch": 2.7640000000000002,
      "grad_norm": 0.04421351104974747,
      "learning_rate": 1.576e-06,
      "loss": 0.0026,
      "step": 6910
    },
    {
      "epoch": 2.768,
      "grad_norm": 0.03349294885993004,
      "learning_rate": 1.5493333333333335e-06,
      "loss": 0.0011,
      "step": 6920
    },
    {
      "epoch": 2.7720000000000002,
      "grad_norm": 0.006990634370595217,
      "learning_rate": 1.5226666666666666e-06,
      "loss": 0.0019,
      "step": 6930
    },
    {
      "epoch": 2.776,
      "grad_norm": 0.13802914321422577,
      "learning_rate": 1.4960000000000002e-06,
      "loss": 0.0011,
      "step": 6940
    },
    {
      "epoch": 2.7800000000000002,
      "grad_norm": 0.08860749006271362,
      "learning_rate": 1.4693333333333335e-06,
      "loss": 0.0083,
      "step": 6950
    },
    {
      "epoch": 2.784,
      "grad_norm": 1.0471330881118774,
      "learning_rate": 1.4426666666666666e-06,
      "loss": 0.0042,
      "step": 6960
    },
    {
      "epoch": 2.7880000000000003,
      "grad_norm": 0.27859795093536377,
      "learning_rate": 1.416e-06,
      "loss": 0.0077,
      "step": 6970
    },
    {
      "epoch": 2.792,
      "grad_norm": 1.0654977560043335,
      "learning_rate": 1.3893333333333334e-06,
      "loss": 0.0025,
      "step": 6980
    },
    {
      "epoch": 2.7960000000000003,
      "grad_norm": 1.2792309522628784,
      "learning_rate": 1.362666666666667e-06,
      "loss": 0.0086,
      "step": 6990
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.0341155007481575,
      "learning_rate": 1.336e-06,
      "loss": 0.0018,
      "step": 7000
    },
    {
      "epoch": 2.8040000000000003,
      "grad_norm": 3.12882661819458,
      "learning_rate": 1.3093333333333335e-06,
      "loss": 0.0024,
      "step": 7010
    },
    {
      "epoch": 2.808,
      "grad_norm": 0.0661688819527626,
      "learning_rate": 1.2826666666666668e-06,
      "loss": 0.0014,
      "step": 7020
    },
    {
      "epoch": 2.8120000000000003,
      "grad_norm": 0.07312587648630142,
      "learning_rate": 1.256e-06,
      "loss": 0.0019,
      "step": 7030
    },
    {
      "epoch": 2.816,
      "grad_norm": 0.013187878765165806,
      "learning_rate": 1.2293333333333334e-06,
      "loss": 0.0088,
      "step": 7040
    },
    {
      "epoch": 2.82,
      "grad_norm": 0.24856053292751312,
      "learning_rate": 1.2026666666666667e-06,
      "loss": 0.006,
      "step": 7050
    },
    {
      "epoch": 2.824,
      "grad_norm": 0.9377670884132385,
      "learning_rate": 1.176e-06,
      "loss": 0.0068,
      "step": 7060
    },
    {
      "epoch": 2.828,
      "grad_norm": 0.006123324856162071,
      "learning_rate": 1.1493333333333334e-06,
      "loss": 0.007,
      "step": 7070
    },
    {
      "epoch": 2.832,
      "grad_norm": 0.33397382497787476,
      "learning_rate": 1.1226666666666667e-06,
      "loss": 0.0093,
      "step": 7080
    },
    {
      "epoch": 2.836,
      "grad_norm": 0.09578962624073029,
      "learning_rate": 1.0960000000000002e-06,
      "loss": 0.0044,
      "step": 7090
    },
    {
      "epoch": 2.84,
      "grad_norm": 0.1373094767332077,
      "learning_rate": 1.0693333333333335e-06,
      "loss": 0.0022,
      "step": 7100
    },
    {
      "epoch": 2.844,
      "grad_norm": 0.14543583989143372,
      "learning_rate": 1.0426666666666668e-06,
      "loss": 0.0017,
      "step": 7110
    },
    {
      "epoch": 2.848,
      "grad_norm": 0.136022686958313,
      "learning_rate": 1.016e-06,
      "loss": 0.0034,
      "step": 7120
    },
    {
      "epoch": 2.852,
      "grad_norm": 0.7072910666465759,
      "learning_rate": 9.893333333333334e-07,
      "loss": 0.002,
      "step": 7130
    },
    {
      "epoch": 2.856,
      "grad_norm": 0.07014793902635574,
      "learning_rate": 9.626666666666667e-07,
      "loss": 0.0014,
      "step": 7140
    },
    {
      "epoch": 2.86,
      "grad_norm": 0.015840059146285057,
      "learning_rate": 9.360000000000001e-07,
      "loss": 0.0093,
      "step": 7150
    },
    {
      "epoch": 2.864,
      "grad_norm": 0.009767167270183563,
      "learning_rate": 9.093333333333334e-07,
      "loss": 0.0005,
      "step": 7160
    },
    {
      "epoch": 2.868,
      "grad_norm": 0.0071552288718521595,
      "learning_rate": 8.826666666666666e-07,
      "loss": 0.0018,
      "step": 7170
    },
    {
      "epoch": 2.872,
      "grad_norm": 0.0038103803526610136,
      "learning_rate": 8.56e-07,
      "loss": 0.0041,
      "step": 7180
    },
    {
      "epoch": 2.876,
      "grad_norm": 0.006228412967175245,
      "learning_rate": 8.293333333333333e-07,
      "loss": 0.0013,
      "step": 7190
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.23338431119918823,
      "learning_rate": 8.026666666666668e-07,
      "loss": 0.0032,
      "step": 7200
    },
    {
      "epoch": 2.884,
      "grad_norm": 0.024122608825564384,
      "learning_rate": 7.760000000000001e-07,
      "loss": 0.001,
      "step": 7210
    },
    {
      "epoch": 2.888,
      "grad_norm": 0.9468172788619995,
      "learning_rate": 7.493333333333335e-07,
      "loss": 0.0036,
      "step": 7220
    },
    {
      "epoch": 2.892,
      "grad_norm": 0.022322794422507286,
      "learning_rate": 7.226666666666668e-07,
      "loss": 0.0023,
      "step": 7230
    },
    {
      "epoch": 2.896,
      "grad_norm": 0.13878071308135986,
      "learning_rate": 6.96e-07,
      "loss": 0.0083,
      "step": 7240
    },
    {
      "epoch": 2.9,
      "grad_norm": 0.008802568539977074,
      "learning_rate": 6.693333333333334e-07,
      "loss": 0.0008,
      "step": 7250
    },
    {
      "epoch": 2.904,
      "grad_norm": 0.05034380406141281,
      "learning_rate": 6.426666666666667e-07,
      "loss": 0.0021,
      "step": 7260
    },
    {
      "epoch": 2.908,
      "grad_norm": 0.01880619302392006,
      "learning_rate": 6.160000000000001e-07,
      "loss": 0.0024,
      "step": 7270
    },
    {
      "epoch": 2.912,
      "grad_norm": 0.1859683245420456,
      "learning_rate": 5.893333333333333e-07,
      "loss": 0.0014,
      "step": 7280
    },
    {
      "epoch": 2.916,
      "grad_norm": 0.0063180807046592236,
      "learning_rate": 5.626666666666667e-07,
      "loss": 0.0009,
      "step": 7290
    },
    {
      "epoch": 2.92,
      "grad_norm": 0.4586605429649353,
      "learning_rate": 5.36e-07,
      "loss": 0.0028,
      "step": 7300
    },
    {
      "epoch": 2.924,
      "grad_norm": 0.09696406126022339,
      "learning_rate": 5.093333333333333e-07,
      "loss": 0.0018,
      "step": 7310
    },
    {
      "epoch": 2.928,
      "grad_norm": 0.012498607859015465,
      "learning_rate": 4.826666666666666e-07,
      "loss": 0.0006,
      "step": 7320
    },
    {
      "epoch": 2.932,
      "grad_norm": 0.05559808760881424,
      "learning_rate": 4.5600000000000006e-07,
      "loss": 0.0022,
      "step": 7330
    },
    {
      "epoch": 2.936,
      "grad_norm": 0.4938591718673706,
      "learning_rate": 4.293333333333333e-07,
      "loss": 0.002,
      "step": 7340
    },
    {
      "epoch": 2.94,
      "grad_norm": 0.294785737991333,
      "learning_rate": 4.0266666666666667e-07,
      "loss": 0.005,
      "step": 7350
    },
    {
      "epoch": 2.944,
      "grad_norm": 0.0044870926067233086,
      "learning_rate": 3.7600000000000003e-07,
      "loss": 0.0021,
      "step": 7360
    },
    {
      "epoch": 2.948,
      "grad_norm": 0.032786328345537186,
      "learning_rate": 3.4933333333333334e-07,
      "loss": 0.009,
      "step": 7370
    },
    {
      "epoch": 2.952,
      "grad_norm": 0.08580070734024048,
      "learning_rate": 3.226666666666667e-07,
      "loss": 0.0011,
      "step": 7380
    },
    {
      "epoch": 2.956,
      "grad_norm": 0.2601582705974579,
      "learning_rate": 2.9600000000000006e-07,
      "loss": 0.0034,
      "step": 7390
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.07063360512256622,
      "learning_rate": 2.6933333333333336e-07,
      "loss": 0.0007,
      "step": 7400
    },
    {
      "epoch": 2.964,
      "grad_norm": 0.3030904233455658,
      "learning_rate": 2.4266666666666667e-07,
      "loss": 0.0005,
      "step": 7410
    },
    {
      "epoch": 2.968,
      "grad_norm": 0.08594057708978653,
      "learning_rate": 2.1600000000000003e-07,
      "loss": 0.0073,
      "step": 7420
    },
    {
      "epoch": 2.972,
      "grad_norm": 0.10741551220417023,
      "learning_rate": 1.8933333333333336e-07,
      "loss": 0.0016,
      "step": 7430
    },
    {
      "epoch": 2.976,
      "grad_norm": 0.8892660140991211,
      "learning_rate": 1.6266666666666667e-07,
      "loss": 0.0012,
      "step": 7440
    },
    {
      "epoch": 2.98,
      "grad_norm": 0.4208242893218994,
      "learning_rate": 1.36e-07,
      "loss": 0.0032,
      "step": 7450
    },
    {
      "epoch": 2.984,
      "grad_norm": 0.050601162016391754,
      "learning_rate": 1.0933333333333335e-07,
      "loss": 0.0012,
      "step": 7460
    },
    {
      "epoch": 2.988,
      "grad_norm": 0.04810357466340065,
      "learning_rate": 8.266666666666668e-08,
      "loss": 0.0045,
      "step": 7470
    },
    {
      "epoch": 2.992,
      "grad_norm": 0.007464688271284103,
      "learning_rate": 5.6000000000000005e-08,
      "loss": 0.0035,
      "step": 7480
    },
    {
      "epoch": 2.996,
      "grad_norm": 0.031463898718357086,
      "learning_rate": 2.9333333333333335e-08,
      "loss": 0.0005,
      "step": 7490
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.01788128912448883,
      "learning_rate": 2.666666666666667e-09,
      "loss": 0.0007,
      "step": 7500
    }
  ],
  "logging_steps": 10,
  "max_steps": 7500,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 7839257057280000.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
